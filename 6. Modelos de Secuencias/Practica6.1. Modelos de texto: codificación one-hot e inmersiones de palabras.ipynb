{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Practica6_1_Modelos_de_texto_codificación_one_hot_e_inmersiones_de_palabras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelamda/DL/blob/master/6.%20Modelos%20de%20Secuencias/Practica6.1.%20Modelos%20de%20texto%3A%20codificaci%C3%B3n%20one-hot%20e%20inmersiones%20de%20palabras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZbMwaaP97Er"
      },
      "source": [
        "# Práctica 6.1. Modelos de Texto\n",
        "\n",
        "En esta práctica vamos a trabajar con las nociones básicas de modelos de texto, o también conocidos como modelos del lenguaje). Primero, haremos una introducción a las inmersiones (embeddings) de palabras, y distintas formas de procesar texto en Keras. También haremos uso de Convoluciones 1D para detectar patrones en las secuencias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BdJTef8Y97Ex",
        "outputId": "b9a0ef2e-ea87-46c2-c600-9565ad2e2454"
      },
      "source": [
        "from tensorflow import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36N76AgD97Ez"
      },
      "source": [
        "## 1. Codificación one-hot de textos\n",
        "\n",
        "La codificación **One-hot**, que ya vimos en nuestros primeros ejemplos con Keras, es la forma más sencilla de transformar texto en vectores numéricos. \n",
        "\n",
        "Consiste, esencialmente, en asociar un índice entero único a cada palabra, y entonces codificar la palabra por medio de un vector de $N$ componentes ($N$ es el tamaño del vocabulario) en el que hay un 1 en la posición del índice de la palabra y 0s en el resto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Earm5lP397Ez"
      },
      "source": [
        "A continuación se muestra una implementación manual de codificación one-hot de texto (por palabra). Este código es solo ilustrativo, después veremos cómo hacer uso de Keras para que haga ésto por nosotros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8N82tu797E0",
        "outputId": "d6fac6c8-3170-4eae-e969-e8c8dca17e48"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Esto es nuestros datos iniciales; una entrada por \"sample\"\n",
        "# (en este ejemplo de juguete, un \"sample\" es tan solo una frase, pero\n",
        "# podría ser un documento entero)\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "# Primero, construimos un indice para todos los tokens en los datos\n",
        "token_index = {}\n",
        "for sample in samples:\n",
        "    # Tokenizamos los samples mediante el método split.\n",
        "    # En la vida real, podríamos también eliminar la puntuación\n",
        "    # y los caracteres especiales de las muestras\n",
        "    for word in sample.split():\n",
        "        if word not in token_index:\n",
        "            # Asignar un índice único a cada palabra única\n",
        "            token_index[word] = len(token_index) + 1\n",
        "            # Observa que no asigamos el índice 0 a nada\n",
        "\n",
        "# A continuación, vectorizamos nuestras muestras.\n",
        "# Sólo consideraremos las primeras palabras `max_length` en cada muestra.\n",
        "max_length = 10\n",
        "\n",
        "# Aquí es donde almacenamos los resultados\n",
        "results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        index = token_index.get(word)\n",
        "        results[i, j, index] = 1.\n",
        "        \n",
        "print(results)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9fAcM_R97E1"
      },
      "source": [
        "Keras proporciona funciones para realizar esta codificación directamente (incluso a nivel de carácter), y es preferible usarlas porque tienen en cuenta una casuística mayor respecto a los caracteres especiales, signos de puntuación, etc. Además, estas funciones permiten definir el tamaño del vocabulario considerando únicamente las $N$ palabras más comunes del dataset e ignorando el resto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ3JFn2m97E1"
      },
      "source": [
        "El siguiente ejemplo muestra cómo se trabaja con las funciones proporcionadas en la librería:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HqqiPlV97E2",
        "outputId": "52a78e84-81b1-4297-b8d3-5aeee983fa59"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "# Creamos un tokenizador, configurado para que sólo tome\n",
        "# en cuenta las 1000 palabras más comunes\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "# Esto construye el índice de palabras\n",
        "tokenizer.fit_on_texts(samples)\n",
        "\n",
        "# Esto convierte las cadenas en listas de índices enteros.\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "\n",
        "# También se pueden obtener directamente las representaciones binarias one-hot.\n",
        "# Ten en cuenta que se admiten otros modos de vectorización además de la codificación one-hot.\n",
        "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
        "\n",
        "# Esto es como puedes recuperar el índice de la palabra que fue calculada\n",
        "word_index = tokenizer.word_index\n",
        "print('Hay %s tokens distintos.' % len(word_index))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 9 tokens distintos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t2QgP8Z97E2"
      },
      "source": [
        "\n",
        "Hay variantes similares para reducir el tamaño del vocabulario por medio de funciones hash, pero no las veremos aquí."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM3eFZkr97E3"
      },
      "source": [
        "## 2. Inmersiones de palabras\n",
        "Otra forma habitual de asociar vectores a palabras es por medio de lo que se conocen como **inmersiones de palabras** (word embedding) o **vectorización densa**. Mientras que los vectores que se obtienen por la codificación one-hot son binarios, muy dispersos (casi todo son 0s) y de dimensión muy alta (el tamaño del vocabulario, que es fácil que alcance las decenas de miles), las inmersiones son de dimensión baja (entre 100 y 1000, aproximadamente), y con vectores de punto flotante. Además, y a difrencia del one-hot, las inmersiones se aprenden a partir de datos.\n",
        "\n",
        "Hay dos formas de obtener estas inmersiones:\n",
        "\n",
        "1. Aprenderlas junto con la tarea en la que se van a utilizar (por ejemplo, clasificación de documentos o análisis de sentimientos). Se sigue un proceso similar al que hemos visto al aprender los pesos de redes neuronales.\n",
        "2. Usando Transfer Learning, reutilizando un modelo de inmersión que ha sido pre-entrenado usando una tarea diferente de ML.\n",
        "\n",
        "Veremos con detalle estos dos métodos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT7jM6fP97E3"
      },
      "source": [
        "### 2.1. Aprendizaje de inmersiones\n",
        "\n",
        "Como el objetivo es que la información semántica de las palabras se refleje en el vector asociado, la asignación aleatoria de vectores a palabras, aunque posible, no tiene ninguna utilidad.\n",
        "\n",
        "El objetivo que se persigue cuando se aprende una inmersión es que las relaciones semánticas y gramaticales existentes entre las palabras del dataset se reflejen en propiedades geométricas de los vectores. Así, dos palabras que tengan un uso/significado similar deberían asociarse a vectores cercanos.\n",
        "\n",
        "Incluso, más allá de la simple distancia, sería deseable que las direcciones vectoriales también tengan algún significado en la inmersión. Cuando hacemos inmersiones de palabras de datasets del mundo real, resulta que las direcciones se asocian a conceptos como “plural” o “género”. Por ejemplo, si sumamos el vector “femenino” al vector asociado a la palabra “rey”, deberíamos obtener el vector asociado a la palabra “reina”, o si le sumamos el vector “plural”, obtenemos el vector asociado a la palabra “reyes”.\n",
        "\n",
        "<img src=\"https://2.bp.blogspot.com/-yL_425HS2ck/WEDZLk5cq0I/AAAAAAAABcI/kwy4F4Cmfi4jyG_InIiYu6F7y2-BKTXWQCLcB/s640/embedding-mnist.gif\" />\n",
        "\n",
        "Estas características no son extrapolables a todos los problemas, y dependen de la tarea concreta que queremos resolver, así pues tiene sentido entrenar la inmersión dependiendo del tipo de tarea a resolver. Para ello Keras introduce un tipo de capa llamada *embedding*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXsRU5yj97E3"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "# Las capas de tipo Embedding toman al menos dos argumentos:\n",
        "# el número de posibles tokens, y la dimensión de inmersión.\n",
        "embedding_layer = Embedding(1000, 64)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzzxhTbd97E4"
      },
      "source": [
        "Una capa *embedding* actúa como un diccionario que asocia índices enteros (palabras) a vectores densos. Formalmente, toma tensores 2D de enteros de tamaño `(samples, sequence_length)`, donde una entrada es una secuencia de enteros, y devuelve un tensor 3D de punto flotante de tamaño `(samples, sequence_length, embedding_dimensionality)`. Este tensor 3D puede ser procesado por las capas adecuadas (por ejemplo, una capa RNN o 1D-convolucional, como veremos más adelante).\n",
        "\n",
        "Cuando se instancia una capa de embedding, sus pesos (diccionario interno de vectores) se inician aleatoriamente, como en cualquier otra capa. Durante el entrenamiento, estos vectores se ajustan gradualmente por medio de la retropropagación, convirtiendo el espacio de vectores en algo que el modelo puede aprovechar. Una vez entrenado, el espacio de inmersión muestra una esctructura que refleja su especialización para el problema específico para el que ha sido entrenado.\n",
        "\n",
        "Vamos a aplicar esta idea al problema de análisis de sentimientos de las opiniones de IMDB que vimos al principio del curso. Vamos a restringirnos solamente a las 10.000 palabras más frecuentes que aparecen en las opiniones, y de cada opinión nos vamos a fijar únicamente en las primeras 20 palabras. La inmersión la haremos sobre un espacio de dimensión muy pequeña, 8D (cada palabra se convierte en un vector denso de 8 posiciones), posteriormente aplanamos esta información, y se la pasamos a una capa densa simple unitaria que realizará la clasificación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY3dz3lU97E4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d153aeb0-28a3-4f40-d029-701db9c4a49d"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "# Número máximo de palabras a considerar como features\n",
        "max_features = 10000\n",
        "\n",
        "# Cargar los datos como listas de enteros.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Truncaremos los textos que tengan más de `maxlen` palabras, o las rellenaremos\n",
        "# con 0s hasta alcanzar este tamaño\n",
        "max_len = 20\n",
        "\n",
        "# x_train y x_test son listas de listas de enteros. Lo siguiente convierte\n",
        "# nuestras listas de enteros en un tensor 2D de enteros `(samples, maxlen)``\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_TThvGn97E4"
      },
      "source": [
        "Creamos el modelo con la capa de inmersión, y realizamos el entrenamiento con los datos leídos:\n",
        "![](https://github.com/miguelamda/DL/blob/master/6.%20Redes%20Recurrentes/model1_plot.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtza5fBE97E5",
        "outputId": "f9c518db-d66a-43f5-a9c2-3c48ce75fa39"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "\n",
        "model = Sequential()\n",
        "# Especificamos la longitud máxima de entrada a nuestra capa de embedding\n",
        "# para que luego podamos aplanar las entradas inmersas\n",
        "model.add(Embedding(10000, 8, input_length=max_len))\n",
        "# Después de la capa de embedding, \n",
        "# nuestras activaciones tienen forma `(samples, max_len, 8)`.\n",
        "\n",
        "# Aplanamos el tensor 3D de los embeddings\n",
        "# en un tensor de forma 2D `(muestras, max_len * 8)``\n",
        "model.add(Flatten())\n",
        "\n",
        "# Añadimos el clasificador en la parte superior\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "#plot_model(model, to_file='model1_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 20, 8)             80000     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 160)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 161       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 80,161\n",
            "Trainable params: 80,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 4ms/step - loss: 0.6771 - acc: 0.5992 - val_loss: 0.6370 - val_acc: 0.6876\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5592 - acc: 0.7447 - val_loss: 0.5339 - val_acc: 0.7270\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4690 - acc: 0.7825 - val_loss: 0.5025 - val_acc: 0.7452\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4247 - acc: 0.8087 - val_loss: 0.4972 - val_acc: 0.7496\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3953 - acc: 0.8242 - val_loss: 0.4952 - val_acc: 0.7516\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3711 - acc: 0.8355 - val_loss: 0.4982 - val_acc: 0.7558\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3498 - acc: 0.8492 - val_loss: 0.5038 - val_acc: 0.7578\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3307 - acc: 0.8583 - val_loss: 0.5119 - val_acc: 0.7564\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3124 - acc: 0.8699 - val_loss: 0.5192 - val_acc: 0.7538\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.2952 - acc: 0.8780 - val_loss: 0.5280 - val_acc: 0.7534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nkd-T4ch97E5"
      },
      "source": [
        "Se consigue una precisión de validación que ronda el ~75%, lo que no está nada mal teniendo en cuenta que solo usamos 20 palabras de cada opinión (comprueba que si subes a 50, la validación alcanza el 80%). \n",
        "\n",
        "El modelo que hemos creado no es muy ajustado, ya que al poner una sola capa densa tras aplanar los datos hace que la posición que ocupa cada palabra no tenga ningún peso en el entrenamiento, y al perder la estructura de las frases se pierde la semántica y solo considera la aparición de ellas (por ejemplo, estas frases, que en inglés significan cosas muy distintas, las considera prácticamente iguales _“this movie is shit”_ y _“this movie is the shit”_). Para evitar este problema sería necesario usar una estructura de red que sí considerase la distribución espacial de las palabras, tal y como las convolucionales 2D hacen con las imágenes. Más adelante veremos cómo aplicar a este problema capas recurrentes o 1D convolucionales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9q8W9vR97E5"
      },
      "source": [
        "### 2.2. Uso de inmersiones preentrenadas\n",
        "\n",
        "Para obtener buenos resultados en inmersiones es necesario disponer de muchos datos, pero cuando los datos que tenemos no son suficientes podemos reusar el entrenamiento realizado en otras tareas, tal y como vimos en módulos anteriores. \n",
        "\n",
        "Al igual que las primeras capas convolucionales de una CNN preentrenada en clases genéricas reflejan relaciones generales útiles acerca de tareas de visión para muchas otras tareas, cuando tratamos con textos, si la tarea en la que se ha entrenado la inmersión no es muy subjetiva, las relaciones geométricas de los vectores de dicha inmersión reflejarán relaciones semánticas generales entre las palabras, que muy probablemente puedan ser útiles para otras tareas que usan el mismo vocabulario.\n",
        "\n",
        "Este tipo de inmersiones de palabras normalmente se contruyen a partir de estadísticas de ocurrencias de palabras (observaciones acerca de qué palabras co-ocurren en frases y documentos), usando diversas técnicas, algunas relacionadas con redes neuronales y otras que no. \n",
        "\n",
        "La idea de una inmersión de palabras densa y de baja dimensión, calculada de forma no supervisada fue inicialmente explorada por Bengio et al. a principios de los 2000, pero su uso real explotó a raíz del esquema de inmersión [Word2Vec](https://en.wikipedia.org/wiki/Word2vec), desarrollado por Mikolov en Google en 2013, que captura propiedades semánticas tales como el género, número, sinonomia, etc.\n",
        "\n",
        "Hay varias bases de datos de inmersiones preentrenadas que se pueden descargar y usar desde las capas de inmersiones de Keras. Word2Vec es una de ellas, y [GloVe (“Global Vectors for Word Representation”)](https://nlp.stanford.edu/projects/glove/) es otra, desarrollada por investigadores de Stanford en 2014, que hace uso de factorización de matrices sobre estadísticas de co-ocurrencias a partir de millones de tokens extraídos de fuentes como la Wikipedia o Common Crawl. Puedes visualizar la inmersión en un espacio tri-dimensional en esta web https://projector.tensorflow.org.\n",
        "\n",
        "Vamos a mostrar cómo usar GloVe en Keras, pero el procedimiento que seguiremos es extrapolable a Word2Vec y otras inmersiones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S-WxZ3n97E6"
      },
      "source": [
        "### 2.3. Del texto en bruto a las inmersiones de palabras\n",
        "\n",
        "Vamos a usar un modelo similar al anterior: \n",
        "* inmersión + \n",
        "* aplanamiento + \n",
        "* capa densa, \n",
        "\n",
        "pero esta vez usaremos una inmersión preentrenada, y en vez de usar el paquete de IMDB pre-tokenizado que proporciona Keras, haremos uso del dataset IMDB con el texto en bruto al completo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2QV3dQE97E7"
      },
      "source": [
        "#### Descarga de IMDB como texto\n",
        "\n",
        "El conjunto de datos sobre el que trabajaremos se puede descargar de http://ai.stanford.edu/~amaas/data/sentiment.\n",
        "\n",
        "En primer lugar, vamos a recolectar las opiniones individuales de entrenamiento como una lista de cadenas, una cadena para cada opinión, junto con las etiquetas asociadas (pos / neg) en una lista labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9DjdDri_QLJ",
        "outputId": "53cfbff3-0b73-4bf3-9340-43b2d9a85db2"
      },
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar xf aclImdb_v1.tar.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-24 16:34:59--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  50.5MB/s    in 1.6s    \n",
            "\n",
            "2022-01-24 16:35:01 (50.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bot8ORc97E7"
      },
      "source": [
        "import os\n",
        "\n",
        "# indica aquí la ruta a la carpeta descargada\n",
        "imdb_dir = './aclImdb/'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-Vs-BV-97E7"
      },
      "source": [
        "#### Tokenizar los datos\n",
        "\n",
        "A continuación vamos a vectorizar los textos que hemos recolectado, y los dividiremos en conjunto de entrenamiento y de validación, de forma similar a como hemos hecho en ejemplos anteriores.\n",
        "\n",
        "Para poner a prueba lo buenas que son las inmersiones pre-entrenadas, vamos a trabajar sobre un conjunto de entrenamiento especialmente pequeño, y consideraremos únicamente 2000 muestras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRBW5uwy97E8",
        "outputId": "4e0d012f-4de2-44dc-fbb4-4cb7395e5c73"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 100  # Recortaremos las críticas después de 100 palabras\n",
        "training_samples = 2000  # Estaremos entrenando con 2000 muestras\n",
        "validation_samples = 10000  # Estaremos validando con 10.000 muestras\n",
        "max_words = 10000  # Sólo consideraremos las 10.000 palabras más importantes del conjunto de datos\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Encontrados %s tokens únicos.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Dividir los datos en un conjunto de entrenamiento y un conjunto de validación\n",
        "# Pero primero, barajar los datos, ya que empezamos a partir de los datos\n",
        "# donde se ordenan las muestras (todas negativas primero, luego todas positivas).\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "xl_train = data[:training_samples]\n",
        "yl_train = labels[:training_samples]\n",
        "xl_val = data[training_samples: training_samples + validation_samples]\n",
        "yl_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 88582 tokens únicos.\n",
            "Shape of data tensor: (25000, 100)\n",
            "Shape of label tensor: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Af2YpD97E8"
      },
      "source": [
        "#### Descargando GloVe\n",
        "\n",
        "Vamos a utilizar la inmersión preentrenada GloVe que ha sido creada a partir de la Wikipedia en inglés en 2014 https://nlp.stanford.edu/projects/glove/. Es un fichero de 822MB llamado `glove.6B.zip`, y contiene una imersión vectorial de 100D de 400.000 palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daWYMElL97E9"
      },
      "source": [
        "#### Preprocesando la inmersión\n",
        "\n",
        "El fichero anterior es un `txt` que debe ser procesado para construir la asociación entre palabras (cadenas) y vectores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otlma854_m-_",
        "outputId": "22608d3e-9dd3-4dcf-fe75-3cf294b343c4"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d glove.6B"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-24 16:35:16--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-01-24 16:35:16--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-01-24 16:35:17--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.16MB/s    in 2m 40s  \n",
            "\n",
            "2022-01-24 16:37:57 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B/glove.6B.50d.txt  \n",
            "  inflating: glove.6B/glove.6B.100d.txt  \n",
            "  inflating: glove.6B/glove.6B.200d.txt  \n",
            "  inflating: glove.6B/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55I__tHa97E9",
        "outputId": "f9db5a64-ece6-499e-9d9d-09e6af2814bc"
      },
      "source": [
        "# indica aquí la ruta a la carpeta descargada\n",
        "glove_dir = 'glove.6B'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Encontrados %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpd09gKr97E9"
      },
      "source": [
        "A continuación, hemos de construir la matriz que cargaremos en la capa de inmersión. Debe tener tamaño `(max_words, embedding_dim)`, donde cada entrada $i$ contiene el vector de tamaño `embedding_dim` para la palabra $i$-ésima en el índice (construido durante la tokenización). El índice 0 no se usa para ninguna palabra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_LmMUuH97E9"
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Las palabras no encontradas en el índice de embedding será todo cero.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1SNiWk897E_"
      },
      "source": [
        "#### Definiendo el modelo\n",
        "\n",
        "Usaremos la misma arquitectura que en el modelo anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwVS065h97E_",
        "outputId": "f496af8d-6529-4964-8fc5-7f25779ae427"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 10000)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                320032    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,320,065\n",
            "Trainable params: 1,320,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnI08muo97E_"
      },
      "source": [
        "#### Cargando la inmersión GloVe en el modelo\n",
        "\n",
        "La capa de inmersión tiene una matriz simple, 2D, de coma flotante, en la que cada entrada $i$ es el vector asociado a la $i$-ésima palabra. Basta cargar la matriz GloVe que hemos preparado antes en la capa de inmersión, que es la primera del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N1RH_3B97E_"
      },
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z96b_c4P97FA"
      },
      "source": [
        "Además, hemos de congelar los pesos de esta capa, para que el entrenamiento posterior no modifique los vectores precargados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7j2OhJE97FA"
      },
      "source": [
        "#### Entrenamiento y Evaluación\n",
        "\n",
        "Compilemos y entrenemos el modelo (y lo grabamos):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzMu1IOR97FA",
        "outputId": "34dbb621-b23c-404e-ec2f-ae02bb7ecca4"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(xl_train, yl_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(xl_val, yl_val))\n",
        "model.save_weights('pre_trained_glove_model.h5')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.8540 - acc: 0.5515 - val_loss: 0.6894 - val_acc: 0.5610\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.5981 - acc: 0.6960 - val_loss: 0.6535 - val_acc: 0.6162\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5381 - acc: 0.7480 - val_loss: 0.6614 - val_acc: 0.6309\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3889 - acc: 0.8240 - val_loss: 0.8882 - val_acc: 0.5554\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.3552 - acc: 0.8460 - val_loss: 1.0784 - val_acc: 0.5620\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.2594 - acc: 0.8965 - val_loss: 0.7041 - val_acc: 0.6480\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.2067 - acc: 0.9150 - val_loss: 0.7495 - val_acc: 0.6452\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.1953 - acc: 0.9335 - val_loss: 0.7760 - val_acc: 0.6443\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.1321 - acc: 0.9615 - val_loss: 0.8979 - val_acc: 0.6344\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.1008 - acc: 0.9660 - val_loss: 1.4044 - val_acc: 0.5769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29I0MS4_97FA"
      },
      "source": [
        "Y mostramos su rendimiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "-NLPa50_97FB",
        "outputId": "f9f5a332-a0a0-4d6c-b40c-c7288489dc10"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5fn/8fcNCBg2ZRMlQrCKuFCWBBAUFZcWl0KxaMHUSl0QWze+tVZ/tEK1fGtbWq2XS4tatZqWWvWLqFirqNWqVYLiAm6AgEFRQEUkINv9++OZhEnIMgmTnJmTz+u65pqZM2fO3HOSfHLOc57zHHN3REQk+zWLugAREUkPBbqISEwo0EVEYkKBLiISEwp0EZGYUKCLiMSEAj3GzOwxMzs73fNGycyWm9kJDbBcN7MDE4//aGY/T2XeenxOoZn9q751itTE1A89s5jZl0lPc4CvgO2J5xe4e1HjV5U5zGw5cJ67P5nm5TpwkLsvSde8ZpYHvA/s4e7b0lGnSE1aRF2AVOTubcse1xReZtZCISGZQr+PmUFNLlnCzI41sxIz+6mZrQbuNLO9zewRM1tjZp8lHucmvecZMzsv8XiCmf3HzGYk5n3fzE6q57y9zOxZM9tgZk+a2c1mdm81dadS47Vm9nxief8ys85Jr59lZivMbJ2ZTalh/Qwxs9Vm1jxp2hgzez3xeLCZvWhmn5vZR2Z2k5m1rGZZd5nZL5Oe/yTxng/N7JxK855iZq+a2Rdm9oGZTUt6+dnE/edm9qWZDS1bt0nvH2Zm881sfeJ+WKrrpo7ruaOZ3Zn4Dp+Z2eyk10ab2cLEd1hqZiMT0ys0b5nZtLKfs5nlJZqezjWzlcBTien/SPwc1id+Rw5Lev+eZva7xM9zfeJ3bE8ze9TMLq70fV43szFVfVepngI9u3QDOgI9gYmEn9+diec9gE3ATTW8fwjwDtAZ+A1wh5lZPeb9K/Ay0AmYBpxVw2emUuOZwA+ArkBL4HIAMzsUuDWx/P0Sn5dLFdz9JWAjcFyl5f418Xg7MDnxfYYCxwM/rKFuEjWMTNRzInAQULn9fiPwfWAv4BTgQjP7duK1oxP3e7l7W3d/sdKyOwKPAjcmvtvvgUfNrFOl77DLuqlCbev5HkIT3mGJZV2fqGEw8BfgJ4nvcDSwvLr1UYVjgEOAbyaeP0ZYT12BV4DkJsIZQD4wjPB7fAWwA7gb+F7ZTGbWD+hOWDdSF+6uW4beCH9YJyQeHwtsAVrXMH9/4LOk588QmmwAJgBLkl7LARzoVpd5CWGxDchJev1e4N4Uv1NVNf4s6fkPgX8mHl8NzEp6rU1iHZxQzbJ/Cfw58bgdIWx7VjPvZcD/JT134MDE47uAXyYe/xm4Lmm+3snzVrHcG4DrE4/zEvO2SHp9AvCfxOOzgJcrvf9FYEJt66Yu6xnYlxCce1cx35/K6q3p9y/xfFrZzznpux1QQw17JebpQPiHswnoV8V8rYHPCMclIAT/LY399xaHm7bQs8sad99c9sTMcszsT4ld2C8Iu/h7JTc7VLK67IG7lyYetq3jvPsBnyZNA/iguoJTrHF10uPSpJr2S162u28E1lX3WYSt8dPMrBVwGvCKu69I1NE70QyxOlHH/xK21mtToQZgRaXvN8TMnk40dawHJqW43LJlr6g0bQVh67RMdeumglrW8/6En9lnVbx1f2BpivVWpXzdmFlzM7su0WzzBTu39Dsnbq2r+qzE7/Tfge+ZWTNgPGGPQupIgZ5dKndJ+jFwMDDE3duzcxe/umaUdPgI6GhmOUnT9q9h/t2p8aPkZSc+s1N1M7v7YkIgnkTF5hYITTdvE7YC2wP/rz41EPZQkv0VmAPs7+4dgD8mLbe2LmQfEppIkvUAVqVQV2U1recPCD+zvap43wfA16pZ5kbC3lmZblXMk/wdzwRGE5qlOhC24stqWAtsruGz7gYKCU1hpV6peUpSo0DPbu0Iu7GfJ9pjpzb0Bya2eIuBaWbW0syGAt9qoBrvB041s6MSBzCvofbf2b8ClxIC7R+V6vgC+NLM+gAXpljDfcAEMzs08Q+lcv3tCFu/mxPt0WcmvbaG0NRxQDXLngv0NrMzzayFmX0XOBR4JMXaKtdR5Xp2948Ibdu3JA6e7mFmZYF/B/ADMzvezJqZWffE+gFYCIxLzF8AjE2hhq8Ie1E5hL2gshp2EJqvfm9m+yW25ocm9qZIBPgO4Hdo67zeFOjZ7QZgT8LWz3+BfzbS5xYSDiyuI7Rb/53wh1yVetfo7ouAHxFC+iNCO2tJLW/7G+FA3VPuvjZp+uWEsN0A3JaoOZUaHkt8h6eAJYn7ZD8ErjGzDYQ2//uS3lsKTAeet9C75ohKy14HnErYul5HOEh4aqW6U1Xbej4L2ErYS/mEcAwBd3+ZcND1emA98G927jX8nLBF/RnwCyru8VTlL4Q9pFXA4kQdyS4H3gDmA58Cv6ZiBv0F6Es4JiP1oBOLZLeZ2d+Bt929wfcQJL7M7PvARHc/KupaspW20KXOzGyQmX0tsYs+ktBuOru294lUJ9Gc9UNgZtS1ZDMFutRHN0KXui8JfagvdPdXI61IspaZfZNwvOFjam/WkRqoyUVEJCa0hS4iEhORDc7VuXNnz8vLi+rjRUSy0oIFC9a6e5eqXoss0PPy8iguLo7q40VEspKZVT67uJyaXEREYkKBLiISEwp0EZGYyKgrFm3dupWSkhI2b95c+8wSidatW5Obm8see+wRdSkiUklGBXpJSQnt2rUjLy+P6q+7IFFxd9atW0dJSQm9evWKuhwRqSSjmlw2b95Mp06dFOYZyszo1KmT9qBE6qmoCPLyoFmzcF+U5ku+Z9QWOqAwz3D6+YjUT1ERTJwIpYlLw6xYEZ4DFBam5zMyagtdRKQhNPSWcSqmTNkZ5mVKS8P0dFGgJ1m3bh39+/enf//+dOvWje7du5c/37JlS43vLS4u5pJLLqn1M4YNG1brPCKSPmVbxitWgPvOLePGDvWVK+s2vT6yOtDT/V+3U6dOLFy4kIULFzJp0iQmT55c/rxly5Zs27at2vcWFBRw44031voZL7zwwu4VKSJ10hhbxqnoUfnihbVMr4+sDfTG+q87YcIEJk2axJAhQ7jiiit4+eWXGTp0KAMGDGDYsGG88847ADzzzDOceuqpAEybNo1zzjmHY489lgMOOKBC0Ldt27Z8/mOPPZaxY8fSp08fCgsLy66Azty5c+nTpw/5+flccskl5ctNtnz5coYPH87AgQMZOHBghX8Uv/71r+nbty/9+vXjyiuvBGDJkiWccMIJ9OvXj4EDB7J06e5cF1gkezTGlnEqpk+HnJyK03JywvS0cfdIbvn5+V7Z4sWLd5lWnZ493UOUV7z17JnyImo0depU/+1vf+tnn322n3LKKb5t2zZ3d1+/fr1v3brV3d2feOIJP+2009zd/emnn/ZTTjml/L1Dhw71zZs3+5o1a7xjx46+ZcsWd3dv06ZN+fzt27f3Dz74wLdv3+5HHHGEP/fcc75p0ybPzc31ZcuWubv7uHHjypebbOPGjb5p0yZ3d3/33Xe9bH3OnTvXhw4d6hs3bnR393Xr1rm7++DBg/3BBx90d/dNmzaVv14fdfk5iUStobOiLu69N3yuWbi/9966LwMo9mpyNeN6uaSqMf/rnn766TRv3hyA9evXc/bZZ/Pee+9hZmzdurXK95xyyim0atWKVq1a0bVrVz7++GNyc3MrzDN48ODyaf3792f58uW0bduWAw44oLyf9/jx45k5c9eLuGzdupWLLrqIhQsX0rx5c959910AnnzySX7wgx+Qk9gU6NixIxs2bGDVqlWMGTMGCCcHiTQV06dX7F0CDbBlnKLCwvT1aKlK1ja5NEZ7VJk2bdqUP/75z3/OiBEjePPNN3n44Yer7ZPdqlWr8sfNmzevsv09lXmqc/3117PPPvvw2muvUVxcXOtBW5GmqrAQZs6Enj3BLNzPnNmwwRqVrA30RmmPqsL69evp3r07AHfddVfal3/wwQezbNkyli9fDsDf/171xenXr1/PvvvuS7NmzbjnnnvYvn07ACeeeCJ33nknpYnNkU8//ZR27dqRm5vL7Nnhsp9fffVV+esiTUFhISxfDjt2hPs4hjlkcaBH9V/3iiuu4KqrrmLAgAF12qJO1Z577sktt9zCyJEjyc/Pp127dnTo0GGX+X74wx9y9913069fP95+++3yvYiRI0cyatQoCgoK6N+/PzNmzADgnnvu4cYbb+TrX/86w4YNY/Xq1WmvXUSiFdk1RQsKCrzyBS7eeustDjnkkEjqySRffvklbdu2xd350Y9+xEEHHcTkyZOjLqucfk4i0TGzBe5eUNVrWbuFHme33XYb/fv357DDDmP9+vVccMEFUZckIlkga3u5xNnkyZMzaotcRLKDttBFRGJCgS4iEhMKdBFpMJkwymFTojZ0EWkQjTH+t1SkLfQkI0aM4PHHH68w7YYbbuDCCy+s9j3HHnssZd0vTz75ZD7//PNd5pk2bVp5f/DqzJ49m8WLF5c/v/rqq3nyySfrUr5IRsmUUQ6bEgV6kvHjxzNr1qwK02bNmsX48eNTev/cuXPZa6+96vXZlQP9mmuu4YQTTqjXskQyQaaMctiUKNCTjB07lkcffbR8XJTly5fz4YcfMnz4cC688EIKCgo47LDDmDp1apXvz8vLY+3atQBMnz6d3r17c9RRR5UPsQuhj/mgQYPo168f3/nOdygtLeWFF15gzpw5/OQnP6F///4sXbqUCRMmcP/99wMwb948BgwYQN++fTnnnHP46quvyj9v6tSpDBw4kL59+/L222/vUpOG2ZWoNOZ4SxJkbBv6ZZfBwoXpXWb//nDDDdW/3rFjRwYPHsxjjz3G6NGjmTVrFmeccQZmxvTp0+nYsSPbt2/n+OOP5/XXX+frX/96lctZsGABs2bNYuHChWzbto2BAweSn58PwGmnncb5558PwM9+9jPuuOMOLr74YkaNGsWpp57K2LFjKyxr8+bNTJgwgXnz5tG7d2++//3vc+utt3LZZZcB0LlzZ1555RVuueUWZsyYwe23317h/V27duWJJ56gdevWvPfee4wfP57i4mIee+wxHnroIV566SVycnL49NNPASgsLOTKK69kzJgxbN68mR07dtRrXYtk0iiHTYW20CtJbnZJbm657777GDhwIAMGDGDRokUVmkcqe+655xgzZgw5OTm0b9+eUaNGlb/25ptvMnz4cPr27UtRURGLFi2qsZ533nmHXr160bt3bwDOPvtsnn322fLXTzvtNADy8/PLB/RKtnXrVs4//3z69u3L6aefXl53qsPs5lQeAU0kRU1plMNMkbFb6DVtSTek0aNHM3nyZF555RVKS0vJz8/n/fffZ8aMGcyfP5+9996bCRMmVDtsbm0mTJjA7Nmz6devH3fddRfPPPPMbtVbNgRvdcPvJg+zu2PHDo2FLo2qocf/loq0hV5J27ZtGTFiBOecc0751vkXX3xBmzZt6NChAx9//DGPPfZYjcs4+uijmT17Nps2bWLDhg08/PDD5a9t2LCBfffdl61bt1KU1Cm3Xbt2bNiwYZdlHXzwwSxfvpwlS5YAYdTEY445JuXvo2F2RZoOBXoVxo8fz2uvvVYe6P369WPAgAH06dOHM888kyOPPLLG9w8cOJDvfve79OvXj5NOOolBgwaVv3bttdcyZMgQjjzySPr06VM+fdy4cfz2t79lwIABFQ5Etm7dmjvvvJPTTz+dvn370qxZMyZNmpTyd9Ewu02TTuhpmjR8rtSZfk6ZrfIJPRAORqr9Oh40fK5IE6ITepouBbpIzOiEnqYr4wI9qiYgSY1+PplPJ/Q0XRkV6K1bt2bdunUKjQzl7qxbt05dHzNcVBdQl+hlVD/03NxcSkpKWLNmTdSlSDVat25Nbm5u1GVIDcoOfE6ZEppZevQIYa4DovGXUi8XMxsJ/AFoDtzu7tdVer0n8GegC/Ap8D13L6lpmVX1chERkZrtVi8XM2sO3AycBBwKjDezQyvNNgP4i7t/HbgG+NXulSySndT/W6KUShv6YGCJuy9z9y3ALGB0pXkOBZ5KPH66itdFYq+s//eKFeC+84IOCnVpLKkEenfgg6TnJYlpyV4DTks8HgO0M7NOlRdkZhPNrNjMitVOLnGj/t8StXT1crkcOMbMXgWOAVYB2yvP5O4z3b3A3Qu6dOmSpo8WyQzq/y1RS6WXyypg/6TnuYlp5dz9QxJb6GbWFviOu+96LTaRGOvRIzSzVDVdpDGksoU+HzjIzHqZWUtgHDAneQYz62xmZcu6itDjRaRJUf9viVqtge7u24CLgMeBt4D73H2RmV1jZmVXbjgWeMfM3gX2AfQrLE2OLuggUcuo0RZFRKRmGm1RRKQJUKCLiMSEAl1EJCYU6CIiMaFAFxGJCQW6iEhMKNBFRGJCgS4iEhMKdBGRmFCgi4jEhAJdRCQmFOgiIjGhQBcRiQkFuohITCjQRURiQoEuIhITCnSJjaIiyMuDZs3CfVFR1BWJNK5ULhItkvGKimDiRCgtDc9XrAjPQZeAk6ZDW+gSC1Om7AzzMqWlYbpIU6FAl1hYubJu00XiSIEusdCjR92mi8SRAl1iYfp0yMmpOC0nJ0wXaSoU6BILhYUwcyb07Alm4X7mTB0QlaZFvVwkNgoLFeDStGkLXUQkJhToIiIxoUAXEYkJBbrsNp1yL5IZdFBUdotOuRfJHNpCl92iU+5FMocCXXaLTrkXyRwKdNktOuVeJHMo0GW36JR7kcyhQJfdolPuRTKHernIbtMp9yKZQVvoIiIxoUAXEYkJBbqISEykFOhmNtLM3jGzJWZ2ZRWv9zCzp83sVTN73cxOTn+pIiJSk1oD3cyaAzcDJwGHAuPN7NBKs/0MuM/dBwDjgFvSXaiIiNQslS30wcASd1/m7luAWcDoSvM40D7xuAPwYfpKFBGRVKQS6N2BD5KelySmJZsGfM/MSoC5wMVVLcjMJppZsZkVr1mzph7liohIddJ1UHQ8cJe75wInA/eY2S7LdveZ7l7g7gVdunRJ00eLiAikFuirgP2TnucmpiU7F7gPwN1fBFoDndNRoIiIpCaVQJ8PHGRmvcysJeGg55xK86wEjgcws0MIga42FRGRRlRroLv7NuAi4HHgLUJvlkVmdo2ZjUrM9mPgfDN7DfgbMMHdvaGKFhGRXaU0lou7zyUc7EyednXS48XAkektTURE6kJnioqIxIQCXUQkJhToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISEwp0EZGYUKCLiMSEAl1EJCYU6CIiMaFAFxGJCQW6iEhMKNBFRGJCgS4iEhMKdBGRmFCgZ7GiIsjLg2bNwn1RUdQViUiUUrpikWSeoiKYOBFKS8PzFSvCc4DCwujqEpHoaAs9S02ZsjPMy5SWhuki0jQp0LPUypV1my4i8adAz1I9etRtuojEnwI9S02fDjk5Fafl5ITpItI0KdCzVGEhzJwJPXuCWbifOVMHREWaMvVyyWKFhQpwEdlJW+giIjGhQBcRiQkFuohITCjQRURiQoEuIhITCnQRkZhQoIuIxIQCXUQkJhToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISEwp0EZGYUKCLiMRESoFuZiPN7B0zW2JmV1bx+vVmtjBxe9fMPk9/qSIiUpNaL3BhZs2Bm4ETgRJgvpnNcffFZfO4++Sk+S8GBjRArSIiUoNUttAHA0vcfZm7bwFmAaNrmH888Ld0FJepioogLw+aNQv3RUVRVyQiklqgdwc+SHpekpi2CzPrCfQCnqrm9YlmVmxmxWvWrKlrrRmhqAgmToQVK8A93E+cqFAXkeil+6DoOOB+d99e1YvuPtPdC9y9oEuXLmn+6MYxZQqUllacVloapouIRCmVQF8F7J/0PDcxrSrjiHlzy8qVdZsuItJYUgn0+cBBZtbLzFoSQntO5ZnMrA+wN/BiekvMLD161G26iEhjqTXQ3X0bcBHwOPAWcJ+7LzKza8xsVNKs44BZ7u4NU2pmmD4dcnIqTsvJCdNFRKJUa7dFAHefC8ytNO3qSs+npa+szFVYGO6nTAnNLD16hDAvmy4iEpWUAl0qKixUgItI5tGp/yIiMaFAFxGJCQW6iEhMKNBFRGJCgS4iEhMKdBGRmFCgi4jEhAJdRCQmFOgiIjGhQBcRiQkFuohITCjQRURiQoEuIhITCnQRkZhQoIuIxIQCXUQkJhToIiIxoSsWiaTZk0/C5ZeHxzk50KZNuE/lVtu8e+wBZtF+P8lcCnSRNHrnHRg7Fjp1gr59obQUNm6EtWvD4+Tb5s11X37z5nX7B9C6dXhPixbhvuzW2M/33hv23DP961sqUqCLpMlnn8G3vgUtW8JTT0HPnjXPv2MHbNq0M/QrB35Vt5rm++STXefbvBm2b2+c71+b7t3ha1+DAw/ceSt73r591NXFgwJdJA22bYPvfheWL08tzAGaNQtb2G3aQJcuDVvfjh2hxu3bd97q8nx337t2LSxZAkuXwty5sHp1xfq6dKkY8MmB36mTmplSpUAXSYMf/xieeAJuvx2OOirqanbVrFnYc8gUX34Zwn3p0hD0Zbdnn4WiInDfOW+HDrtu0ZfdunVT2CdToIvspttvhxtvhMsug3PPjbqa7NC2LfTrF26Vbd4M77+/c4u+LOyLi+H++ys2IeXkVAz55Me5uaH9vikxT/5X2IgKCgq8uLg4ks8WSZfnnoPjj4fjjoNHHgkHA6XhbN0KK1fuDPnkwF+2DL76aue8LVtCr14Vt+i//e0Q9NnMzBa4e0GVrynQRepn+XIYNAg6doSXXoK99oq6oqZtxw5YtapiE05y4G/cGNrj//EPGDEi6mrrr6ZA1/ZEFtq8GV57DebPh1deCVuIhYVRV9W0fPkljB4dthjnzFGYZ4JmzWD//cOtcmC7w6JFcMYZcOKJcP31cNFF8Wt/V6BnuG3bYPHiEN5ltzfeCEECoYfEnXeGXc1zzom21qZixw446yx480147DE4+OCoK5LamMHhh8N//wvf+x5ccgm8+irceiu0ahV1demjQM8g7mEXcf58ePnlcP/qq6E/MYSj/QUFoUfFoEHh1rVr2FI8/3xo1w5OPz3a79AUTJ0Ks2eHrbxvfCPqaqQu2rcPP7tp0+Daa+Gtt+DBB2HffaOuLD3Uhh6hVasqbnkXF4eTUyCc4TdgQAjtwYPD/YEHht3KykpL4ZvfDO24c+bAyJGN+z2akr//HcaNC3tDt98ev132puSBB+Dss8OG0oMPwpAhUVeUGh0UzQCffloxvOfPh48+Cq81bx5OEy/b6h40CA47LIzbkar160O74dtvw+OPw/DhDfM9mrIFC0If8/x8mDcvXrvqTdXrr4c93A8/hD/9CSZMiLqi2inQG9nGjeFgZXJ4L1268/WDD64Y3v37p2ecizVr4Oijwy/n00/DwIG7v0wJPvoo/KyaNw8/z65do65I0mXt2nCW71NPwaWXwowZmd39VL1cGtCWLeG/fHJ4L14cDpxBOOI+aBCcd164z89vuB4RXbqEsxWPOio0wTz7LBxySMN8VlOyeTOMGROaw55/XmEeN507h73ayy+HP/whdDq4777QxTHbKNDrwT20n952W+g+uGVLmN65cwjt007bufW9zz6NW1tubhi+9aijQves//wH8vIat4Y4cYeJE8PxiQceCHtTEj8tWsANN4Sf7wUXhL/dhx4KTaHZRBe4qKONG+H73w9/5Dt2hF20++4Lpyp/8kkYeOgXv4BTT238MC9z4IFhS720FE44YWdbvdTdjBlwzz1wzTXhH7XE24QJ8O9/h72yoUPDP/Gs4u6R3PLz8z3bvPuue9++7mbu117rvn171BXV7MUX3du0cT/8cPd166KuJvs88kj4WZ9xhvuOHVFXI41p1Sr3IUPcwf3nP8+sv3Wg2KvJVW2hp+ihh0If8FWrwskkP/tZ1V0IM8kRR4RujO+9ByedBBs2RF1R9li0CMaPD11H77xT3RObmv32g2eegR/8IPRXHzMGvvgi6qpql+GRFL1t2+Cqq8KgPr17h94r3/xm1FWl7rjjQt/pBQtC96z6XCWnqVm3DkaNCiP5zZ4d7qXpad0a7rgjjKT56KNhA+m996KuqmYK9Bp88kkI7+uuC23mzz2X2oULMs3o0XD33WGL44wzdg4bILvaujWcbVtSEsJ8//2jrkiiZAYXXwz/+hd8/HE4ye/xx6OuqnopBbqZjTSzd8xsiZldWc08Z5jZYjNbZGZ/TW+Zje+ll0IXw+efhz//OZx00Lp11FXVX2Eh3HQTPPxwOPBT1q1SKrrsstCH/7bbwhaZCIQ93eJi6NEDTj45HCyP6BSemlXXuF52A5oDS4EDgJbAa8ChleY5CHgV2DvxvGtty83Ug6I7drjfcov7Hnu45+W5L1gQdUXp9atfhQM9kybpQF9lt94a1s3ll0ddiWSqDRvcx44NvyeFhe6lpY1fAzUcFE0l0IcCjyc9vwq4qtI8vwHOq21ZybdMDPSNG93POiuslZNPjm/PkJ/+NHzHK6+MupLM8fTT7i1ahJ/7tm1RVyOZbMcO91/+MvwN5ee7r1zZuJ9fU6Cn0uTSHfgg6XlJYlqy3kBvM3vezP5rZlUOD2VmE82s2MyK16xZk8JHN54lS0K/03vvDf3IH344XLggjn71K5g0KRwbuO66qKuJ3rJl8J3vwEEHwV//2vQuWyZ1YwZTpoSeb+++G3q//ec/UVcVpOugaAtCs8uxwHjgNjPb5QR3d5/p7gXuXtCloS9zXgdz5oQfSklJODHo6qszv0vi7jCDm2+GM88MPXhuvTXqiqLzxRehR4t7+D3o0CHqiiRbjBoVjrV16BDa2GfOjLqi1AJ9FZB8rD83MS1ZCTDH3be6+/vAu4SAz2jbt4f/tKNHh7MrFyxoOkPPNmsGd90F3/oW/OhH4UrrTc327eFiB2+/HS5LduCBUVck2eaQQ0KoH3dcGDLgwgt3DgUSieraYnxn+3gLYBnQi50HRQ+rNM9I4O7E486EJppONS036jb0Tz5xP+GE0A523keRh2UAAAgrSURBVHnumzZFWk5kNm1yHzHCvXlz94ceirqaxnXlleHnf9NNUVci2W7bNvef/CT8Pg0f7v7xxw33WezOQdHwfk4mbHUvBaYkpl0DjEo8NuD3wGLgDWBcbcuMMtBfesl9//3dW7Vyv+OOyMrIGF984T54cFgf8+ZFXU3juPfe8Nt/wQXq7SPpU1Tk3rp1yJeG6iFXU6A3qfHQ3UN/8ksvDaf2PvCAxgwv8+mncMwxYZCxefOy5+ot9fHyy2Hc+COOCIOY1eVCIiK1WbAgDBWwZk04h2X8+PQuv6bx0GN86K+i0tIwLsOFF8Lxx4eVrjDfqWPHcDbcPvuEcV/eeCPqihrGqlVhGIf99oP771eYS/rl54eTkAoKQseDn/40HK9pDE0i0JcuhWHD4C9/CReHfeSR+HZJ3B377hvGUs/JCWOpL1kSdUXptWlTCPMNG0KPls6do65I4qpr17CnO2kS/OY3YTjtsusFN6TYB/ojj4T/mCtXhgF2pk6Nd5fE3dWrV2iG2LYtjKVeUhJ1RenhDueeG/bMiorg8MOjrkjirmXL0CX4j38MG0pDhsBbbzXsZ8Y22rZvD0Pcfutb8LWvhT/kk06KuqrscMghYQCizz4LW+oZdg5YvfzqV/C3v8H06aH/sEhjueCCcL3Szz8Pof7www33WbEM9LVrQ3hPnx62yp5/Pmx5Sury88PezfLlYcTJ9eujrqj+HnoonG9w5plwZZVDy4k0rOHDQ7v6QQeF817uuKNhPid2gT5/fgijZ58NI+bdfnt2j5IYpeHD4cEH4c03QxtgaWnUFdXdG2+EkSYHDQq/C7pQhUSlR48wBPcFF8CIEQ3zGbEJ9LIuiUcdFf5on38ezjsv6qqy30knhTbnF14I451EehZcHa1ZE5pX2reH//s/2HPPqCuSpi4nJ7SrH3BAwyw/FoG+aROcc044onzccaG9PD8/6qri4/TTwzgV//xn2NptrC5Yu2PLFhg7FlavDheq6F55ODmRGMr6QF+2LHRJvPvu0IPlkUegU6eoq4qfc8+F3/0u9N2eODGzL5DhHq4y8+yzoa1y8OCoKxJpHC2iLmB3PPpoGFzJLAT5ySdHXVG8/c//hIOj11wTmjF+//vMbJO++eawR3HVVeFAqEhTkZWBvn17GLP82mvDVdkfeEC9WBrLtGmh+9UNN8Dee4ehhjPJvHnhMnKjRsEvfxl1NSKNK+sCfd26sNX1r3+FdvObbtLBrsZkBtdfH8YRnzo1jAV96aWN89nbt4cDnatX73r7+ONwX1wc+tHfe69OIJOmJ+sC/cYb4d//Dl0S1YslGs2ahfW/YUPYGm7fPoyTUx/u4QSm6gI6+bZmTdUX5m3XDrp1C+PQjB4dtszbtdu97yiSjbIu0KdMCb0X+vaNupKmrUWL0J1xw4bwj7Vdu/BzKfPll7UHdNn0rVt3XX6rViGgu3WDvLwwMmK3bjuDO/lxmzaN9rVFMlpWBXpRUQj0lStDJ/3p00M3OolGq1bhxKNvfCM0g11//c7g3rhx1/mbNQuDFpWF8eGH7xrQZbcOHTLzgKtIJsuaQC8qCt3lys5WXLEiPAeFepTatAm9jSZODMc3hgypOqC7dQvdSXUBZpGGkzUXuMjLCyFeWc+eYbwREZGmIBYXuFi5sm7TRUSamqwJ9B496jZdRKSpyZpAnz49DGyTLCcnTBcRkSwK9MLCcDp3z56h90PPnuG5DoiKiARZ08sFQngrwEVEqpY1W+giIlIzBbqISEwo0EVEYkKBLiISEwp0EZGYiOzUfzNbA1RxMn9W6QysjbqIDKL1sZPWRUVaHxXtzvro6e5dqnohskCPAzMrrm5MhaZI62MnrYuKtD4qaqj1oSYXEZGYUKCLiMSEAn33zIy6gAyj9bGT1kVFWh8VNcj6UBu6iEhMaAtdRCQmFOgiIjGhQK8HM9vfzJ42s8VmtsjMLo26pqiZWXMze9XMHom6lqiZ2V5mdr+ZvW1mb5nZ0KhripKZTU78nbxpZn8zs9ZR19RYzOzPZvaJmb2ZNK2jmT1hZu8l7vdO1+cp0OtnG/Bjdz8UOAL4kZkdGnFNUbsUeCvqIjLEH4B/unsfoB9NeL2YWXfgEqDA3Q8HmgPjoq2qUd0FjKw07UpgnrsfBMxLPE8LBXo9uPtH7v5K4vEGwh9s92irio6Z5QKnALdHXUvUzKwDcDRwB4C7b3H3z6OtKnItgD3NrAWQA3wYcT2Nxt2fBT6tNHk0cHfi8d3At9P1eQr03WRmecAA4KVoK4nUDcAVwI6oC8kAvYA1wJ2JJqjbzaxN1EVFxd1XATOAlcBHwHp3/1e0VUVuH3f/KPF4NbBPuhasQN8NZtYWeAC4zN2/iLqeKJjZqcAn7r4g6loyRAtgIHCruw8ANpLGXepsk2gfHk34R7cf0MbMvhdtVZnDQ7/xtPUdV6DXk5ntQQjzInd/MOp6InQkMMrMlgOzgOPM7N5oS4pUCVDi7mV7bPcTAr6pOgF4393XuPtW4EFgWMQ1Re1jM9sXIHH/SboWrECvBzMzQhvpW+7++6jriZK7X+Xuue6eRzjY9ZS7N9ktMHdfDXxgZgcnJh0PLI6wpKitBI4ws5zE383xNOGDxAlzgLMTj88GHkrXghXo9XMkcBZha3Rh4nZy1EVJxrgYKDKz14H+wP9GXE9kEnsq9wOvAG8QMqfJDANgZn8DXgQONrMSMzsXuA440czeI+zBXJe2z9Op/yIi8aAtdBGRmFCgi4jEhAJdRCQmFOgiIjGhQBcRiQkFuohITCjQRURi4v8DS+12VPAJUxoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaJ8Y2F_97FB"
      },
      "source": [
        "El modelo se sobreajusta muy rápido, algo que no es extraño teniendo en cuenta el tamaño reducido del conjunto de entrenamiento. Consecuentemente, la validación tiene una alta varianza y apenas supera el 63% en el mejor de los casos.\n",
        "\n",
        "Observa que, debido a la selección aleatoria del pequeño conjunto de entrenamiento, los resultados pueden variar mucho si se vuelve a ejecutar el procedimiento.\n",
        "\n",
        "También podemos intentar realizar el entrenamiento sin haber precargado una inmersión y sin congelar la capa de inmersión. Es decir, aprendiendo la inmersión específica de la tarea que estamos llevando a cabo. Esta opción, como comentamos, suele ser mejor si se dispone de los recursos computacionales necesarios y de muchos datos, pero nosotros lo entrenamos únicamente con 2000 muestras."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Usando Convolución 1D\n",
        "\n",
        "En Keras, se puede usar una convnet 1D a través de la capa `Conv1D`, que tiene una interfaz muy similar a `Conv2D`. Toma como entrada tensores 3D con forma `(samples, time, features)` y también devuelve tensores 3D de forma similar. La ventana de convolución es una ventana 1D en el eje temporal (es decir, eje 1, *time*, en el tensor de entrada).\n",
        "\n",
        "Las convnets 1D están estructuradas de la misma manera que sus versiones 2D que ya hemos utilizado en módulo 5: consisten en una pila de capas `Conv1D` y `MaxPooling1D`, terminando eventualmente en una capa de `globalPooling` o una capa `Flatten`, convirtiendo las salidas 3D en salidas 2D, permitiendo añadir una o más capas `Dense` al modelo, para hacer clasificación o regresión.\n",
        "\n",
        "Una diferencia, sin embargo, es el hecho de que podemos permitirnos el lujo de usar ventanas de convolución más grandes con convnets 1D. De hecho, con una capa de convolución 2D, una ventana de convolución 3x3 contiene vectores con `3*3 = 9` características, pero con una capa de convolución 1D, una ventana de convolución de tamaño 3 sólo contendría vectores con 3 características. De esta manera podemos permitirnos fácilmente ventanas de convolución 1D de tamaño 7 o 9.\n",
        "\n",
        "Este es nuestro ejemplo de convneto 1D para el conjunto de datos IMDB:"
      ],
      "metadata": {
        "id": "_MEvVqRFkFQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "modelConv1D = Sequential()\n",
        "# Aquí podemos ver que podemos crear una capa de embedding con los pesos\n",
        "# pre-entrenados directamente en la creación de la capa\n",
        "modelConv1D.add(layers.Embedding(max_words, \n",
        "                                 embedding_dim, \n",
        "                                 input_length=maxlen,\n",
        "                                 embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                                 trainable=False))\n",
        "modelConv1D.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "modelConv1D.add(layers.MaxPooling1D(5))\n",
        "modelConv1D.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "modelConv1D.add(layers.GlobalMaxPooling1D())\n",
        "modelConv1D.add(layers.Dense(1))\n",
        "\n",
        "modelConv1D.summary()\n",
        "\n",
        "modelConv1D.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "                    loss='binary_crossentropy',\n",
        "                   metrics=['acc'])\n",
        "history = modelConv1D.fit(xl_train, yl_train,\n",
        "                          epochs=10,\n",
        "                          batch_size=32,\n",
        "                         validation_data=(xl_val, yl_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1uLYefbkO4J",
        "outputId": "30707b03-7f62-4a8d-a6d8-496755d97b41"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 94, 32)            22432     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 18, 32)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 12, 32)            7200      \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 32)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,029,665\n",
            "Trainable params: 29,665\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 10s 29ms/step - loss: 1.3167 - acc: 0.5200 - val_loss: 0.9492 - val_acc: 0.5140\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.8022 - acc: 0.5585 - val_loss: 0.8257 - val_acc: 0.5325\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.7351 - acc: 0.5975 - val_loss: 0.8375 - val_acc: 0.5381\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.6593 - acc: 0.6185 - val_loss: 0.8243 - val_acc: 0.5392\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.6325 - acc: 0.6525 - val_loss: 0.7934 - val_acc: 0.5530\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.5968 - acc: 0.6965 - val_loss: 0.8237 - val_acc: 0.5632\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.5579 - acc: 0.7350 - val_loss: 0.7959 - val_acc: 0.5760\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.5215 - acc: 0.7685 - val_loss: 0.8735 - val_acc: 0.5821\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.4825 - acc: 0.7960 - val_loss: 0.9651 - val_acc: 0.5880\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.4499 - acc: 0.8195 - val_loss: 0.8587 - val_acc: 0.5977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veremos, cuando hagamos uso de redes recurrentes como la LSTM, que el tiempo de entrenamiento es muy alto. Sin embargo, el tiempo de ejecución de una Conv1D es más rápido, tanto en la CPU como en la GPU (aunque la velocidad exacta variará mucho dependiendo de la configuración)."
      ],
      "metadata": {
        "id": "0k3_jO_DnC8t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "7x9RntOT97FB",
        "outputId": "6badab66-4646-4da5-87d6-58f68df66e32"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9vQIMw797FC"
      },
      "source": [
        "Apenas conseguimos un 60% de accuracy en validación, un valor muy bajo que nos indica que en efecto trabajar con tan pocos ejemplos de entrenamiento lo convierte en una tarea dura.\n",
        "\n",
        "Vamos a intentarlo de nuevo con más ejemplos, usemos el dataset IMDB que nos provee Keras, ya pre-tokenizado. Pongamos una capa de Embedding vacía."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelConv1D_2 = Sequential()\n",
        "modelConv1D_2.add(layers.Embedding(max_features, output_dim=128, input_length=max_len ))\n",
        "modelConv1D_2.add(layers.Conv1D(32, 11, activation='relu'))\n",
        "modelConv1D_2.add(layers.Conv1D(16, 7, activation='relu'))\n",
        "modelConv1D_2.add(layers.GlobalMaxPooling1D())\n",
        "modelConv1D_2.add(layers.Dense(1))\n",
        "\n",
        "modelConv1D_2.summary()\n",
        "\n",
        "modelConv1D_2.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = modelConv1D_2.fit(x_train, y_train,\n",
        "                            epochs=10,\n",
        "                            batch_size=128,\n",
        "                            validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TrnHi8L7xzK",
        "outputId": "5caaae5f-3c30-4114-ca53-ce09c0e67f40"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_21 (Embedding)    (None, 20, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_31 (Conv1D)          (None, 10, 32)            45088     \n",
            "                                                                 \n",
            " conv1d_32 (Conv1D)          (None, 4, 16)             3600      \n",
            "                                                                 \n",
            " global_max_pooling1d_16 (Gl  (None, 16)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,328,705\n",
            "Trainable params: 1,328,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 2s 7ms/step - loss: 0.9863 - acc: 0.5121 - val_loss: 0.6768 - val_acc: 0.5714\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.6516 - acc: 0.6231 - val_loss: 0.6405 - val_acc: 0.6300\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.5925 - acc: 0.6926 - val_loss: 0.5995 - val_acc: 0.6730\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.5337 - acc: 0.7386 - val_loss: 0.5796 - val_acc: 0.6916\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.4926 - acc: 0.7695 - val_loss: 0.5848 - val_acc: 0.7082\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4604 - acc: 0.7894 - val_loss: 0.5980 - val_acc: 0.7158\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4365 - acc: 0.8061 - val_loss: 0.6178 - val_acc: 0.7236\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.4122 - acc: 0.8209 - val_loss: 0.6528 - val_acc: 0.7280\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3899 - acc: 0.8332 - val_loss: 0.6748 - val_acc: 0.7282\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3702 - acc: 0.8424 - val_loss: 0.6951 - val_acc: 0.7290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora mucho mejor. Conseguimos un rendimiento mucho mejor, similar al obtenido al comienzo de la práctica. Jugando con la arquitectura y los hiperparámetros podríamos conseguir una mejora sustancial."
      ],
      "metadata": {
        "id": "XxxFan_iFU-g"
      }
    }
  ]
}