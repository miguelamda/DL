{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelamda/DL/blob/master/Ejercicios/Ejercicio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkHEHL9WLDeu"
      },
      "source": [
        "# Ejercicio 2. Entrenamiento de modelos de clasificación con Keras\n",
        "\n",
        "En este segundo ejercicio tendrás que trabajar con Keras para probar las técnicas que has visto hasta la Práctica 5.2, incluyendo regularización (L2, dropout, data augmentation, K-validación cruzada, etc.), capas convolucionales, pooling, densas, etc. con **al menos 4 configuraciones** distintas. Además, emplearás tu modelo con tu webcam.\n",
        "\n",
        "Para ello, vas a tener que trabajar con un conjunto de datos sobre imágenes de personas que llevan o no máscara. \n",
        "\n",
        "![mask](https://github.com/miguelamda/DL/blob/master/Ejercicios/img/mask.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec_TFbA5LAs-"
      },
      "source": [
        "## 1. Enunciado\n",
        "\n",
        "Empleando el dataset de mascarillas (ver apartado 3), debes construir y probar **al menos 4** configuraciones de modelos con Keras que sean sustancialmente distintas. Debes jugar con:\n",
        "* K-validación o validación cruzada.\n",
        "* Regularización: L1/L2, early stopping, dropout.\n",
        "* Data augmentation: echando un vistazo al dataset, ¿qué tipo de transformación harías? ¿qué transformaciones NO harías? ¿qué ventaja se obtiene al usar aumentado?.\n",
        "* Distintas arquitecturas de redes convolucionales: distinta cantidad y orden de capas convolucionales, pooling, densas, etc.\n",
        "* Distintos optimizadores (Adam, RMSprop, momentum, etc.), factor de aprendizaje y número de épocas.\n",
        "\n",
        "Después, entrénalas con los datos leídos y analiza los resultados, haciendo una comparativa y razonando lo obtenido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFfMGuPz4VDN"
      },
      "source": [
        "## 2. Entrega\n",
        "\n",
        "La entrega de este ejercicio se realiza a través de la tarea creada para tal efecto en Enseñanza Virtual. Tienes que entregar un notebook, y el HTML generado a partir de él, cuyas celdas estén ya evaluadas.\n",
        "\n",
        "La estructura del notebook debe contener los siguientes apartados:\n",
        "\n",
        "0. Cabecera: nombre y apellidos.\n",
        "1. Dataset: descripción, carga y visualización.\n",
        "2. Preparación de los datos para ser usados en Keras.\n",
        "3. Modelos y configuraciones creados en Keras (un sub-apartado para cada uno, explicando de forma razonada, con tus palabras y figuras, la arquitectura probada).\n",
        "4. Entrenamiento y evaluación de cada modelo creado (un sub-apartado para cada uno).\n",
        "5. Análisis de resultados.\n",
        "6. Bibliografía utilizada (enlaces web, material de clase, libros, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPR7zuh34VDO"
      },
      "source": [
        "### 2.1. Nota importante\n",
        "-----\n",
        "**HONESTIDAD ACADÉMICA Y COPIAS: un trabajo práctico es un examen, por lo que\n",
        "debe realizarse de manera individual. La discusión y el intercambio de\n",
        "información de carácter general con los compañeros se permite (e incluso se\n",
        "recomienda), pero NO AL NIVEL DE CÓDIGO. Igualmente el remitir código de\n",
        "terceros, OBTENIDO A TRAVÉS DE LA RED o cualquier otro medio, se considerará\n",
        "plagio.** \n",
        "\n",
        "**Cualquier plagio o compartición de código que se detecte significará\n",
        "automáticamente la calificación de CERO EN LA ASIGNATURA para TODOS los\n",
        "alumnos involucrados. Por tanto a estos alumnos NO se les conservará, para\n",
        "futuras convocatorias, ninguna nota que hubiesen obtenido hasta el momento.\n",
        "SIN PERJUICIO DE OTRAS MEDIDAS DE CARÁCTER DISCIPLINARIO QUE SE PUDIERAN\n",
        "TOMAR.**\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaZbFh0Z4VDP"
      },
      "source": [
        "## 3. El Dataset: Mask Dataset <a class=\"anchor\" id=\"transferdata\"></a>\n",
        "\n",
        "Este pequeño dataset está disponible en Kaggle. Es una versión reducida del construido en [este tutorial](https://www.pyimagesearch.com/2020/05/04/covid-19-face-mask-detector-with-opencv-keras-tensorflow-and-deep-learning/). La pandemia originada por el SARS-Cov2 ha propiciado la creación de diversos datasets para detectar si las personas están llevando mascarilla o no. En este dataset para este ejeercicio, tenemos imágenes de personas con y sin mascarilla (algunas se les ha puesto la mascarilla de forma \"artificial\"). El enlace al dataset es el siguiente [Face Mask Detection](https://www.kaggle.com/omkargurav/face-mask-dataset). Si no tienes cuenta en Kaggle, o si quieres ir más rápido, puedes ejecutar la siguiente celda. Descargará el dataset directamente en tu sesión/ordenador desde un enlace directo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ9XsOqX4VDR"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import pathlib\n",
        "\n",
        "# Esta función de Keras descargará el dataset en $HOME/.keras\n",
        "data_path = keras.utils.get_file(\n",
        "    \"mask_dataset.zip\",\n",
        "    \"https://hdvirtual.us.es/discovirt/index.php/s/dijNRMPYfybYd3N/download\",\n",
        "    extract=True,\n",
        "    archive_format='zip'\n",
        ")\n",
        "\n",
        "# La siguiente variable contiene la ruta al dataset. Puedes evaluarla\n",
        "# y después hacer !ls para ver el contenido\n",
        "DATA_FOLDER = pathlib.Path(data_path).parent / 'mask_ds' \n",
        "!ls $DATA_FOLDER\n",
        "\n",
        "# Puedes usar el siguiente tamaño de imagen\n",
        "IMAGE_SIZE = (128, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Despliegue del modelo pre-entrenado\n",
        "\n",
        "Una vez hayas entrenado un modelo (por ejemplo, `model`), puedes lanzar una de las siguientes celdas para hacer la prueba con tu WebCam. No es necesario que adjuntes capturas tuyas, pero sí que se valorará que hagas varias pruebas y analices el ratio de aciertos de tu modelo.\n",
        "\n",
        "## 4.1 Capturando la WebCam desde Google Colab\n",
        "\n",
        "Lanza las siguientes dos celdas para capturar una foto con tu web cam, si estás en Google Colab. Haz clic en el botón \"Capture\" (guardará la imagen en `image.jpg`)."
      ],
      "metadata": {
        "id": "oVgYi9OE84W7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjTIFhFO4VDS"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='image.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Fz9tTGju4VDS"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEFejbor4VDT"
      },
      "source": [
        "##4.2 Capturando la WebCam desde local\n",
        "\n",
        "El siguiente código debería permitirte capturar una foto desde tu webcam si estás en local."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYxG6-re4VDT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display, update_display\n",
        "\n",
        "main_text = \"\"\"\n",
        "<video id=\"video\" width=\"320\" height=\"240\" autoplay style=\"display:none\"></video>\n",
        "<canvas id=\"canvas\" width=\"320\" height=\"240\"  ></canvas>\n",
        "\n",
        "<script>\n",
        "// Grab elements, create settings, etc.\n",
        "var video = document.getElementById('video');\n",
        "\n",
        "// Get access to the camera!\n",
        "if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
        "    // Not adding `{ audio: true }` since we only want video now\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {\n",
        "        //video.src = window.URL.createObjectURL(stream);\n",
        "        //video.play();\n",
        "        video.srcObject=stream;\n",
        "        video.play();\n",
        "    });\n",
        "}\n",
        "\n",
        "// Elements for taking the snapshot\n",
        "var canvas = document.getElementById('canvas');\n",
        "var context = canvas.getContext('2d');\n",
        "var video = document.getElementById('video');\n",
        "\n",
        "\n",
        "// Trigger photo take\n",
        "\n",
        "setInterval(function() {\n",
        "    context.drawImage(video, 0, 0, 320, 240);\n",
        "    var myCanvas = document.getElementById('canvas');\n",
        "    var image = myCanvas.toDataURL(\"image/png\");\n",
        "    IPython.notebook.kernel.execute(\"image = '\" + image + \"'\")\n",
        "    \n",
        "}, 2);\n",
        "\n",
        "</script>\n",
        "\n",
        "\"\"\"\n",
        "HTML(main_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf2PRtjJ4VDT"
      },
      "source": [
        "#4.3 Evaluando el modelo\n",
        "\n",
        "La siguiente celda debería permitirte cargar un modelo guardado en la variable `model`, y usarlo para hacer predicción con la imagen capturada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "zvc5fq8G4VDT"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import base64\n",
        "from numpy import asarray\n",
        "import io\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "#pil_im = Image.open(io.BytesIO(base64.b64decode(image.split(',')[1]))) # versión en local\n",
        "pil_im = Image.open(filename)  # versión en google colab\n",
        "pil_im = pil_im.convert('RGB')\n",
        "pil_im = pil_im.resize(IMAGE_SIZE, Image.ANTIALIAS)\n",
        "pil_im"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im = np.asarray(pil_im) / 255\n",
        "print(model.predict(np.array([im])).argmax())  # Muestra la salida del modelo y el resultado (con o sin mascarilla)\n",
        "result = 'con mascarilla' if model.predict(np.array([im])).argmax() == 0 else 'sin mascarilla'\n",
        "print(result)"
      ],
      "metadata": {
        "id": "1EnM-Ee9_kvy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "3 Maneras de Programar a una Red Neuronal.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}