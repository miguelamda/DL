{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los ejemplos presentados en los temas anteriores hemos comprobado que en la validación el rendimiento de todos los modelos presenta un máximo tras unas pocas epochs y entonces comienza a degradarse, es decir, que los modelos comienzan a *sobreajustarse* a los datos de entrenamiento sin que haya dado tiempo a extraer patrones suficientemente útiles de ellos para poder ser aplicados sobre datos no vistos.\n",
    "\n",
    "![](./imgs/TestTraining.png)\n",
    "\n",
    "Como hemos comentado más veces, el sobreajuste es común a todos los problemas de ML, y se hace más patente cuanta menor cantidad de datos tengamos para entrenar. Por ello, saber reconocerlo y dar pautas para mitigar sus efectos se convierten en tareas esenciales para obtener buenos resultados en la aplicación de técnicas de ML/DL.\n",
    "\n",
    "El problema fundamental de ML (y, en general, de muchas otras técnicas de la IA) es la tensión existente entre **optimización** y **generalización**, donde la optimización se considera respecto al proceso de ajustar un modelo para conseguir el mejor rendimiento posible sobre los datos de entrenamiento (es donde se concentra la parte de _aprendizaje_ en el  Aprendizaje Automático), y la generalizacion es respecto a lo bien que el modelo entrenado se comporta sobre datos que no ha visto anteriormente. El objetivo, por supuesto, es conseguir una buena generalización, pero es precisamente la parte que no podemos controlar, ya que solo podemos ajustar el modelo en función los datos de entrenamiento.\n",
    "\n",
    "Cuando el entrenamiento empieza, la optimización y la generalización están correladas (sobre todo, teniendo en cuenta que normalmente se comienza con un modelo cuya asignación de pesos es aleatoria): cuanto menor es el error sobre los datos de entrenamiento, menor es sobre los datos de test. En esta fase se dice que el modelo tiene _under-fitting_, es decir, que todavía  puede mejorar porque la red todavía no ha modelado todos los patrones relevantes existentes en los datos de entrenamiento. Pero tras un cierto número de iteraciones sobre los datos de entrenamiento, la generalización deja de mejorar, y las métricas de validación empiezan a empeorar: el modelo comienza a *sobreajustarse* (*overfitting*), es decir, comienza a aprender patrones que son específicos de los datos de entrenamiento pero que no caracterizan otros datos.\n",
    "\n",
    "Para prevenir que un modelo aprenda este tipo de patrones irrelevantes de los datos de entrenamiento, la mejor solución, por supuesto, es conseguir mayor, y lo más variada posible, cantidad de datos de entrenamiento. Es como cualquier proceso de aprendizaje, automático o natural: un modelo entrenado con más datos tendrá más herramientas para extrapolar su aprendizaje a situaciones nuevas. \n",
    "\n",
    "Pero no siempre es posible conseguir más datos, bien porque el suceso del que se han obtenido está fuera de nuestro alcance, o bien porque sea tremendamente costoso preparar un proceso de adquisición de datos adicional. En este caso, y aunque pueda parecer contradictorio, una buena solución es limitar la capacidad de aprendizaje del modelo, bien sea limitando la cantidad de información que el modelo puede almacenar, o añadiendo restricciones al tipo de información que se puede almacenar. Si una red solo puede memorizar un pequeño número de patrones, el proceso de optimización forzará al modelo a enfocarse en los patrones más importantes, aquellos que tienen más opciones de generalizar bien dentro de los datos de entrenamiento y, en consecuencia, es probable que también funcionen mejor en los datos nuevos.\n",
    "\n",
    "El conjunto de técnicas que se han desarrollado para luchar contra el sobreajuste se conoce de forma genérica como **Regularización**.\n",
    "\n",
    "En este tema vamos a revisar algunas de las técnicas más comunes de regularización y aplicarlas de forma práctica para mejorar el modelo de clasificación de opiniones de películas en IMDB que vimos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a preparar los datos usados en el módulo anterior para reutilizarlos ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Como hemos comentado, la forma más simple de reducir el sobreajuste es incrementando el tamaño del conjunto de entrenamiento. Sin embargo, en ML no suele ser fácil porque a menudo los datos etiquetados son costosos.\n",
    "\n",
    "En general, esta dificultad es insalvable, pero en casos particulares, como cuando trabajamos con imágenes, hay algunas formas de incrementar el tamaño del conjunto de entrenamiento por medio de operaciones básicas: traslación, rotación, escalado, volteado, etc.\n",
    "\n",
    "![](./imgs/DataAugmentation.png)\n",
    "\n",
    "Como esta técnica es mucho más común en el trabajo con imágenes, dejaremos su análisis más detallado al tema en el que trabajemos con Redes Convolucionales, que son especialmente apropiadas para este tipo de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parada temprana (early stopping)\n",
    "\n",
    "La parada temprana es un tipo de estrategia basada en validación cruzada de la que hemos hecho uso (manualmente) en ejemplos anteriores: cuando observamos que el rendimiento en validación comienza a empeorar, paramos el entrenamiento del modelo.\n",
    "\n",
    "En keras podemos aplicar esta técnica usando las funciones de callbacks, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "EarlyStopping(monitor='val_err', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta función, `monitor` representa la métrica que debe ser monitorizada (`val_err` es el error de validación). `Patience` denota el número de eopchs consecutivas que se pueden dejar pasar sin que se haya registrado una mejoría, si se superan, el entrenamiento para."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduciendo el tamaño de la red\n",
    "\n",
    "La forma más sencilla de evitar el sobreajuste es reducir el tamaño del modelo, es decir, el número de parámetros ajustables por él (que viene  determinado por el número de capas y el número de unidades por capa). \n",
    "\n",
    "En Deep Learning, el número de parámetros ajustables en un modelo se denomina a menudo **capacidad del modelo**. Intuitivamente, un modelo con más parámetros tendrá más *capacidad de memorización* y, por tanto, podrá usar su aprendizaje para construir un diccionario que asocia perfectamente cada muestra de entrenamiento con su salida esperada. Obviamente, un aprendizaje basado en la memorización no tiene posibilidades de generalizar correctamente. \n",
    "\n",
    "Por ejemplo, un modelo con 500.000 parámetros binarios podría fácilmente aprender la clase de cada dígito en el problema MNIST: sólo necesitaríamos 10 parámetros binarios para cada uno de los 50.000 dígitos. Un modelo de este tipo sería inútil para clasificar nuevas muestras de dígitos si éstas presentan diferencias sustanciales, porque no ha extraido patrones que pueda usar en otros casos, sino solo ha memorizado las características propias de cada dato visto en el entrenamiento. \n",
    "\n",
    "Recordemos un hecho fundamental: los modelos de Deep Learning (debido al número de parámetros que tienen) suelen ser buenos para adaptarse a los datos de entrenamiento, pero el verdadero desafío del aprendizaje es la generalización, no el ajuste perfecto.\n",
    "\n",
    "Sin embargo, si la red tiene recursos limitados para memorizar, no podrá construir ese diccionario de una forma satisfactoria (salvo que haya pocos datos de entrenamiento) y, en consecuencia, para minimizar la pérdida durante el entrenamiento tendrá que recurrir al aprendizaje de patrones (que no son más que representaciones comprimidas) que le permitan ajustarse al mayor número posible de datos vistos. Este es precisamente el tipo de representaciones que interesa. \n",
    "\n",
    "No podemos ser muy extremistas, al mismo tiempo que limitamos la capacidad de almacenamiento del modelo, ha de tenerse en cuenta que se deben utilizar modelos que tengan suficientes parámetros para que la complejidad de la estructura aprendida por el modelo no sea demasiado simple, es decir, hay que llegar a un equilibrio entre un \"modelo memorizante\" y un \"modelo inútil\".\n",
    "\n",
    "Por desgracia, no existe una fórmula mágica para determinar cuál es el número correcto de capas, o cuál es el tamaño correcto para cada capa, por lo que habrá que evaluar una colección de arquitecturas diferentes para encontrar aquella que es más adecuada al problema que se quiere resolver y a los datos que tenemos de él. El flujo de trabajo general para encontrar un tamaño apropiado es comenzar con relativamente pocas capas y aumentar el tamaño de las mismas, o añadir nuevas capas, hasta que se obtenga un rendimiento decreciente en la pérdida en validación (no en entrenamiento, que, salvo casos extraños, siempre tenderá a mejorar).\n",
    "\n",
    "Probemos esto en nuestra red de clasificación de opiniones de películas. La red original era:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "red_original = models.Sequential()\n",
    "red_original.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "red_original.add(layers.Dense(16, activation='relu'))\n",
    "red_original.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "red_original.compile(optimizer='rmsprop',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/IMDBModel_plot.png)\n",
    "\n",
    "Como hemos comentado, vamos a comenzar reduciendo el tamaño de la red y comprobando cómo se comporta con la reducción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_pequena = models.Sequential()\n",
    "red_pequena.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
    "red_pequena.add(layers.Dense(4, activation='relu'))\n",
    "red_pequena.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "red_pequena.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "\n",
    "plot_model(red_pequena, to_file='IMDBModelPeq_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/IMDBModelPeq_plot.png)\n",
    "\n",
    "Vamos a comparar los resultados de pérdida en validación de ambas redes (recuerda que cuanto menor es la pérdida en validación, mejor es el modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 11s 446us/step - loss: 0.4549 - acc: 0.8190 - val_loss: 0.3413 - val_acc: 0.8759\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.2597 - acc: 0.9084 - val_loss: 0.3029 - val_acc: 0.8794\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 6s 225us/step - loss: 0.1998 - acc: 0.9272 - val_loss: 0.3055 - val_acc: 0.8753\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 6s 224us/step - loss: 0.1718 - acc: 0.9376 - val_loss: 0.2914 - val_acc: 0.8842\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 6s 253us/step - loss: 0.1449 - acc: 0.9498 - val_loss: 0.3133 - val_acc: 0.8780\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.1267 - acc: 0.9563 - val_loss: 0.3269 - val_acc: 0.8764\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 6s 228us/step - loss: 0.1104 - acc: 0.9627 - val_loss: 0.3661 - val_acc: 0.8692\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 6s 246us/step - loss: 0.0989 - acc: 0.9672 - val_loss: 0.3835 - val_acc: 0.8680\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 6s 225us/step - loss: 0.0862 - acc: 0.9716 - val_loss: 0.3983 - val_acc: 0.8674\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 6s 237us/step - loss: 0.0771 - acc: 0.9755 - val_loss: 0.4331 - val_acc: 0.8630\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 6s 258us/step - loss: 0.0653 - acc: 0.9797 - val_loss: 0.4599 - val_acc: 0.8632\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 6s 244us/step - loss: 0.0591 - acc: 0.9820 - val_loss: 0.4837 - val_acc: 0.8616\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 6s 231us/step - loss: 0.0513 - acc: 0.9854 - val_loss: 0.5111 - val_acc: 0.8591\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 6s 231us/step - loss: 0.0425 - acc: 0.9878 - val_loss: 0.6133 - val_acc: 0.8443\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 224us/step - loss: 0.0381 - acc: 0.9901 - val_loss: 0.5793 - val_acc: 0.8573\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 6s 243us/step - loss: 0.0319 - acc: 0.9916 - val_loss: 0.6080 - val_acc: 0.8568\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.0286 - acc: 0.9923 - val_loss: 0.6460 - val_acc: 0.8537\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 6s 224us/step - loss: 0.0241 - acc: 0.9936 - val_loss: 0.6876 - val_acc: 0.8516\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 6s 235us/step - loss: 0.0192 - acc: 0.9956 - val_loss: 0.7402 - val_acc: 0.8464\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 7s 273us/step - loss: 0.0157 - acc: 0.9966 - val_loss: 0.7502 - val_acc: 0.8512\n"
     ]
    }
   ],
   "source": [
    "entrenamiento_original = red_original.fit(x_train, y_train,\n",
    "                                   epochs=20,\n",
    "                                   batch_size=512,\n",
    "                                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 6s 240us/step - loss: 0.5563 - acc: 0.7939 - val_loss: 0.4615 - val_acc: 0.8579\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 6s 235us/step - loss: 0.3753 - acc: 0.8895 - val_loss: 0.3558 - val_acc: 0.8787\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 6s 235us/step - loss: 0.2827 - acc: 0.9113 - val_loss: 0.3054 - val_acc: 0.8870\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 6s 221us/step - loss: 0.2311 - acc: 0.9234 - val_loss: 0.2845 - val_acc: 0.8894\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 7s 271us/step - loss: 0.1985 - acc: 0.9327 - val_loss: 0.2788 - val_acc: 0.8889\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 6s 240us/step - loss: 0.1753 - acc: 0.9400 - val_loss: 0.2816 - val_acc: 0.8879\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 6s 225us/step - loss: 0.1575 - acc: 0.9469 - val_loss: 0.2865 - val_acc: 0.8860\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 6s 225us/step - loss: 0.1442 - acc: 0.9510 - val_loss: 0.2978 - val_acc: 0.8824\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 6s 233us/step - loss: 0.1313 - acc: 0.9568 - val_loss: 0.3074 - val_acc: 0.8799\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 6s 228us/step - loss: 0.1214 - acc: 0.9604 - val_loss: 0.3242 - val_acc: 0.8772\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 7s 264us/step - loss: 0.1112 - acc: 0.9648 - val_loss: 0.3364 - val_acc: 0.8756\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 6s 228us/step - loss: 0.1028 - acc: 0.9670 - val_loss: 0.3575 - val_acc: 0.8730\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 6s 234us/step - loss: 0.0948 - acc: 0.9711 - val_loss: 0.3706 - val_acc: 0.8712\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 6s 245us/step - loss: 0.0878 - acc: 0.9728 - val_loss: 0.3862 - val_acc: 0.8698\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 234us/step - loss: 0.0817 - acc: 0.9753 - val_loss: 0.4058 - val_acc: 0.8661\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 6s 236us/step - loss: 0.0747 - acc: 0.9782 - val_loss: 0.4246 - val_acc: 0.8651\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 250us/step - loss: 0.0698 - acc: 0.9802 - val_loss: 0.4445 - val_acc: 0.8642\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 6s 231us/step - loss: 0.0644 - acc: 0.9823 - val_loss: 0.4696 - val_acc: 0.8600\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 6s 236us/step - loss: 0.0598 - acc: 0.9837 - val_loss: 0.4856 - val_acc: 0.8604\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 7s 263us/step - loss: 0.0551 - acc: 0.9856 - val_loss: 0.5107 - val_acc: 0.8580\n"
     ]
    }
   ],
   "source": [
    "entrenamiento_red_pequena = red_pequena.fit(x_train, y_train,\n",
    "                                       epochs=20,\n",
    "                                       batch_size=512,\n",
    "                                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 21)\n",
    "original_val_loss = entrenamiento_original.history['val_loss']\n",
    "red_pequena_val_loss = entrenamiento_red_pequena.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Red Original')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, red_pequena_val_loss, 'bo', label='Red Pequeña')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Pérdida Validación')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Como se puede observar, la red pequeña comienza a sobreajustar más tarde que la original (tras 6 epochs, en vez de 4) y su rendimiento se degrada mucho más lentamente una vez que ha empezado a empeorar.\n",
    "\n",
    "Ahora, por probrar, vamos a añadir una red con mucha más capacidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_grande = models.Sequential()\n",
    "red_grande.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\n",
    "red_grande.add(layers.Dense(512, activation='relu'))\n",
    "red_grande.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "red_grande.compile(optimizer='rmsprop',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 10s 386us/step - loss: 0.4630 - acc: 0.7954 - val_loss: 0.2848 - val_acc: 0.8882\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 9s 357us/step - loss: 0.2237 - acc: 0.9120 - val_loss: 0.3084 - val_acc: 0.8730\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 9s 353us/step - loss: 0.1352 - acc: 0.9494 - val_loss: 0.3076 - val_acc: 0.8851\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 9s 363us/step - loss: 0.0763 - acc: 0.9792 - val_loss: 0.4175 - val_acc: 0.8808\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 9s 370us/step - loss: 0.0818 - acc: 0.9856 - val_loss: 0.4809 - val_acc: 0.8818\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 9s 359us/step - loss: 0.0728 - acc: 0.9882 - val_loss: 0.4978 - val_acc: 0.8729\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 9s 379us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6401 - val_acc: 0.8789\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 9s 363us/step - loss: 1.9125e-04 - acc: 1.0000 - val_loss: 0.7594 - val_acc: 0.8787\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 9s 369us/step - loss: 0.1095 - acc: 0.9881 - val_loss: 0.7476 - val_acc: 0.8781\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 9s 364us/step - loss: 5.5737e-04 - acc: 1.0000 - val_loss: 0.7769 - val_acc: 0.8779\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 9s 371us/step - loss: 2.0219e-05 - acc: 1.0000 - val_loss: 0.8623 - val_acc: 0.8781\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 10s 393us/step - loss: 3.3496e-06 - acc: 1.0000 - val_loss: 0.9439 - val_acc: 0.8774\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 9s 369us/step - loss: 5.9520e-07 - acc: 1.0000 - val_loss: 1.0177 - val_acc: 0.8777\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 9s 368us/step - loss: 1.8911e-07 - acc: 1.0000 - val_loss: 1.0676 - val_acc: 0.8779\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 9s 378us/step - loss: 1.2898e-07 - acc: 1.0000 - val_loss: 1.0911 - val_acc: 0.8780\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 9s 366us/step - loss: 1.1806e-07 - acc: 1.0000 - val_loss: 1.1053 - val_acc: 0.8781\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 9s 379us/step - loss: 1.1434e-07 - acc: 1.0000 - val_loss: 1.1139 - val_acc: 0.8780\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 9s 377us/step - loss: 1.1264e-07 - acc: 1.0000 - val_loss: 1.1191 - val_acc: 0.8778\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 9s 373us/step - loss: 1.1174e-07 - acc: 1.0000 - val_loss: 1.1231 - val_acc: 0.8778\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 9s 358us/step - loss: 1.1123e-07 - acc: 1.0000 - val_loss: 1.1267 - val_acc: 0.8778\n"
     ]
    }
   ],
   "source": [
    "entrenamiento_red_grande = red_grande.fit(x_train, y_train,\n",
    "                                     epochs=20,\n",
    "                                     batch_size=512,\n",
    "                                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ponerla también en comparación con la original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_grande_val_loss = entrenamiento_red_grande.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Red Original')\n",
    "plt.plot(epochs, red_grande_val_loss, 'bo', label='Red Grande')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Pérdida Validación')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La red grande comienza a sobreajustar desde el principio, tras la primera iteración, y el sobreajuste es mucho más severo que en la red original. Además, su pérdida de validación presenta también mucho más ruido.\n",
    "\n",
    "Si comparamos las pérdidas de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_train_loss = entrenamiento_original.history['loss']\n",
    "red_grande_train_loss = entrenamiento_red_grande.history['loss']\n",
    "\n",
    "plt.plot(epochs, original_train_loss, 'b+', label='Red Original')\n",
    "plt.plot(epochs, red_grande_train_loss, 'bo', label='Red Grande')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Pérdida Entrenamiento')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la red grande consigue que su pérdida de entrenamiento sea prácticamente nula muy rápido. Mostrando que, como habíamos dicho anteriormente, cuanto mayor es la capacidad de la red, más rápido modela los datos de entrenamiento a la perfección, pero también más susceptible es al sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizando los pesos\n",
    "\n",
    "Principio de _la navaja de Occam_: \"si se dan dos explicaciones distintas para un mismo suceso, la explicación correcta más probable es la más simple, la que hace el menor número de suposiciones adicionales\". \n",
    "\n",
    "Como método que aspira a ser estándar en el avance del conocimiento, este mismo principio también se aplica a los modelos aprendidos por las redes neuronales: si fijamos los datos de entrenamiento y una arquitectura de red, hay múltiples asignaciones de pesos (lo que se traduce en múltiples _modelos_) que podrían explicar los datos, y los modelos más sencillos tienen menos probabilidad de sobreajustar que los más complejos.\n",
    "\n",
    "Un *modelo sencillo* en este contexto es un modelo en el que la distribución de valores de los parámetros que lo definen tiene menos entropía (o un modelo que tiene en total menos parámetros, como vimos en la sección anterior). Por lo tanto, una forma común de mitigar el sobreajuste es poner límites a la complejidad de la red forzando que sus pesos tomen un rango de valores pequeños, lo que hace que la distribución de estos valores sea más _regular_. \n",
    "\n",
    "A este procedimiento, en general, se le llama **regularización de los pesos**, y se consigue añadiendo a la función de pérdida de la red un _coste_ asociado a tener grandes pesos. \n",
    "\n",
    "Este coste aidiconal suele venir dado de dos formas:\n",
    "\n",
    "* **Regularización L1 (Lasso)**: el coste es proporcional al _valor absoluto de los pesos_ (matemáticamente, la norma L1 de los pesos). Suele dar como resultado que muchos pesos tomen el valor 0, por lo que a veces se identifica con un procedimiento de compresión de la red.\n",
    "\n",
    "$$Coste= Loss + \\frac{\\lambda}{2n}\\sum |w|$$\n",
    "\n",
    "* **Regularización L2 (Ridge)**: el coste es proporcional al _cuadrado de los valores de los pesos_ (matemáticamente, la normal L2 de los pesos). En el contexto de las redes neuronales, a esta norma también se le llama _weight decay_, ya que fuerza a que los pesos tiendan a 0.\n",
    "$$Coste= Loss + \\frac{\\lambda}{2n}\\sum |w|^2$$\n",
    "\n",
    "En ambos casos, $\\lambda$ es el factor de regularización aplicado.\n",
    "\n",
    "En Keras, la regularización de los pesos se añade pasando instancias adecuadas de regularizadores a las capas por medio de argumentos específicos. Por ejemplo, si quisiéramos añadir una regularización L2 al modelo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "red_l2 = models.Sequential()\n",
    "red_l2.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', input_shape=(10000,)))\n",
    "red_l2.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "red_l2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "red_l2.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`l2(0.001)` significa que cada coeficiente de la matriz de pesos de la capa añadirá un total de `0.001 * peso` al valor de pérdida total de la red. Debe tenerse en cuenta que, como esta penalización solo se aplica en tiempo de entrenamiento, la pérdida que se obtiene al regularizar es mucho mayor para el entrenamiento que para el test.\n",
    "\n",
    "El impacto de esta reguarización en nuestro ejemplo sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 7s 261us/step - loss: 0.4864 - acc: 0.8299 - val_loss: 0.3778 - val_acc: 0.8822\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.3150 - acc: 0.9044 - val_loss: 0.3368 - val_acc: 0.8859\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 6s 233us/step - loss: 0.2698 - acc: 0.9204 - val_loss: 0.3403 - val_acc: 0.8820\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 6s 243us/step - loss: 0.2518 - acc: 0.9271 - val_loss: 0.3336 - val_acc: 0.8873\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 6s 225us/step - loss: 0.2394 - acc: 0.9314 - val_loss: 0.3926 - val_acc: 0.8636\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.2296 - acc: 0.9352 - val_loss: 0.3451 - val_acc: 0.8824\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.2248 - acc: 0.9364 - val_loss: 0.3527 - val_acc: 0.8811\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 6s 240us/step - loss: 0.2200 - acc: 0.9410 - val_loss: 0.3724 - val_acc: 0.8750\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 6s 236us/step - loss: 0.2127 - acc: 0.9434 - val_loss: 0.3797 - val_acc: 0.8733\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 6s 226us/step - loss: 0.2105 - acc: 0.9448 - val_loss: 0.3904 - val_acc: 0.8704\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 6s 224us/step - loss: 0.2081 - acc: 0.9456 - val_loss: 0.4028 - val_acc: 0.8672\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 7s 268us/step - loss: 0.2032 - acc: 0.9466 - val_loss: 0.4214 - val_acc: 0.8637\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 7s 296us/step - loss: 0.2004 - acc: 0.9478 - val_loss: 0.4068 - val_acc: 0.8668\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 6s 248us/step - loss: 0.2032 - acc: 0.9460 - val_loss: 0.3980 - val_acc: 0.8706\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 242us/step - loss: 0.1978 - acc: 0.9491 - val_loss: 0.4089 - val_acc: 0.8687\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 7s 280us/step - loss: 0.1950 - acc: 0.9503 - val_loss: 0.3998 - val_acc: 0.8714\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 250us/step - loss: 0.1965 - acc: 0.9490 - val_loss: 0.4028 - val_acc: 0.8696\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 6s 226us/step - loss: 0.1927 - acc: 0.9488 - val_loss: 0.4070 - val_acc: 0.8700\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 6s 227us/step - loss: 0.1909 - acc: 0.9494 - val_loss: 0.4108 - val_acc: 0.8674\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 6s 238us/step - loss: 0.1859 - acc: 0.9523 - val_loss: 0.4147 - val_acc: 0.8690\n"
     ]
    }
   ],
   "source": [
    "entrenamiento_red_l2 = red_l2.fit(x_train, y_train,\n",
    "                             epochs=20,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XucFPWZ7/HPw8WMKGIUdV2BGXRRLl6GYcICogmJt4iiEV1BktXEhJjo4po9q5icyEjiObqS3cQVY8boi5wwCSZZTdCDEWO8BBNXGTIauSjIRYcQRYwIEcIAz/5RNU0zdPd0T0919eX7fr361VXV1dXPFEU9Vb9f1VPm7oiIiAD0iDsAEREpHkoKIiKSoKQgIiIJSgoiIpKgpCAiIglKCiIikqCkICIiCUoKIiKSoKQgIiIJveIOIFf9+/f3mpqauMMQESkpzc3N77j7UZ3NV3JJoaamhqVLl8YdhohISTGzDdnMp+YjERFJUFIQEZEEJQUREUkouT6FVNra2mhtbWXnzp1xhyJFqKqqigEDBtC7d++4QxEpemWRFFpbW+nbty81NTWYWdzhSBFxd7Zs2UJrayuDBw+OOxyRolcWzUc7d+7kyCOPVEKQA5gZRx55pM4ipSw0NET/G2WRFAAlBElL24aUi1tvjf43yiYpiIhI/pQUuknPnj2pra3l5JNP5sILL+S9997L6fsNDQ3MmTMn5WeNjY0MHTqUoUOHMnr0aJYsWZJ2Obfccgu/+tWvMv7WwoULuf3223OKL9mhhx7a5e+KSG4aGsAseMG+4aiakio6KXTnSj344INpaWnhlVde4YgjjmDu3LndstxHH32U733veyxZsoRVq1Zx7733csUVV/CnP/3pgHn37NnD7NmzOeusszIuc9KkScycObNb4hORaDU0gHvwgn3DSgoRiKp9buzYsWzcuDExfuedd/KRj3yEU089lVmzZiWm33bbbZx00kmcddZZvPrqqymXdccdd3DnnXfSv39/AOrq6rjyyisTSaempobZs2czfvx4fvrTn3LVVVfxs5/9DIBFixYxdOhQxo8fz4wZM7jgggsAmDdvHtdddx0AV111FTNmzGDcuHEcf/zxie9u376dT3ziE9TV1XHKKafwi1/8opvXkkjlKURHcb4qOilEYc+ePTz55JNMmjQJgMWLF7N69WpeeOEFWlpaaG5u5tlnn6W5uZkFCxbw+9//noceeogXX3wx5fKWL1/OqFGj9ptWX1/P8uXLE+NVVVUsWbKEKVOmJKbt3LmTL37xizz22GMsWbKEzZs3p41506ZNLFmyhEcffTRxBlFVVcXDDz/MsmXLeOqpp/iXf/kXvP1QRUS6JN8D0aRjyshUXFKIqn1ux44d1NbWcuSRR/Luu+9y9tlnA0FSWLx4MSNHjqSuro5Vq1axevVqfvOb3/CpT32KPn36cNhhhyWSSDbcfb8rai6//PID5lm1ahXHH3984tr8qVOnpl3exRdfTI8ePRg+fDhvvfVW4je++tWvcuqpp3LWWWexcePGxGciEg9dkhqBqNrn2vsUNmzYwK5duxLNO+7OzTffTEtLCy0tLaxZs4arr74ayO5SyeHDh9Pc3LzftGXLljF8+PDE+CGHHHLA93I5qv/Qhz50wPeamprYvHkzzc3NtLS0cMwxx+haf5EuKHRHcb4qLilErV+/ftx1113MmTOHtrY2zj33XB544AG2b98OwMaNG3n77bc588wzefjhh9mxYwfbtm3jkUceSbm8G2+8kZtuuoktW7YA0NLSwrx58/jyl7+cMY6hQ4eydu1a1q9fD8CDDz6Y09+xdetWjj76aHr37s1TTz3Fhg1ZVd0VkQ4K3VGcr7Ioc9FVUbXPjRw5ktNOO40FCxbwmc98hpUrVzJ27FgguJxz/vz51NXVcfnll1NbW0t1dTVnnHFGymVNmjSJjRs3Mm7cOMyMvn37Mn/+fI499tiMMRx88MHcc889nHfeefTv35/Ro0fn9DdMmzaNCy+8kPr6empraxk6dGhO3xeR0mSl1nlYX1/vHR+ys3LlSoYNGxZTRMVr+/btHHroobg71157LUOGDOGGG26IO6xYaBuRYtDQEN8Zgpk1u3t9Z/Op+aiM3XfffdTW1jJixAi2bt3KF7/4xbhDEqloxdpklKyim4/K3Q033FCxZwYi0jU6UxARkQQlBRERSVBSEBGRBCUFERFJUFLoJlGVzk41/c0332TChAkMGzaMESNG8J3vfCev2LuqKyW0zz///JzXTUdPP/10orifiHSvikwKTU1QUwM9egTvTU35LzOq0tmp9OrVi29961usXLmS559/nrlz57JixYqM33F39u7dG1lMnWn//UWLFnH44YfHFoeIZFZxSaGpCaZPhw0bglvNN2wIxrsjMbTrztLZqRx77LHU1dUB0LdvX4YNG7bf77Vbv349w4YN48tf/jJ1dXW8+eabLF68mLFjx1JXV8dll12WKL+Rrsx2xzOVk08+OVE6o126Mtupfr+mpoZ33nmHe++9l9raWmpraxk8eDATJkwA4Etf+hL19fWMGDFiv3X1y1/+MhHfQw89lJj+wgsvMG7cOEaOHMm4ceNyWo8ikoK7R/YCzgNeBdYAM1N8/h9AS/h6DXivs2WOGjXKO1qxYsUB09Kprm6vPLL/q7o660WkdMghh7i7++7du/3SSy/1xx57zN3dH3/8cf/CF77ge/fu9T179vjEiRP9mWee8aVLl/rJJ5/sf/nLX3zr1q1+wgkn+J133nnAcmfNmpVyert169b5wIEDfevWrSk/MzP/3e9+5+7umzdv9jPOOMO3b9/u7u63336733rrrb5jxw4fMGCAr1271t3dp0yZ4hMnTkz5+yNGjPB169bt9ze3tbUlfn/z5s1+wgkn+N69ew/4fXf36upq37x5c2J8165dPn78eF+4cKG7u2/ZsiWxHj/60Y/6Sy+9lIjvtdde87179/pll12WiG/r1q3e1tbm7u5PPPGEX3LJJSnXUy7biEg5ApZ6FvvtyG5eM7OewFzgbKAVeNHMFrp7op3D3W9Imv+fgJFRxdPujTdym56t9tLZ69evZ9SoUSlLZ0NwVL169Wq2bduWKJ0N5FQ6u9327duZPHky3/72tznssMNSzlNdXc2YMWMAeP7551mxYgWnn346ALt27WLs2LEpy2w3NjZmHYeHZbafffZZevTosV+Z7eTfT+X666/n4x//OBdeeCEAP/nJT2hsbGT37t1s2rSJFStWsHfvXgYPHsyQIUMA+PSnP52Ib+vWrVx55ZWsXr0aM6OtrS3ruEXkQFE2H40G1rj7WnffBSwALsow/1TgxxHGA8CgQblNz1ZUpbPTaWtrY/LkyUybNo1LLrkECDqg25tk7r33XmD/struztlnn52IZcWKFdx///0Zy2z36tVrv76IVOWzM5XZTlXWu928efPYsGFDoplo3bp1zJkzhyeffJKXX36ZiRMnJpaTbl19/etfZ8KECbzyyis88sgjKu8tkqcok8JxwJtJ463htAOYWTUwGPh1hPEAcNttEB6cJ/TpE0zvDt1dOjsVd+fqq69m2LBhfOUrX0lMHzhwYGKHf8011xzwvTFjxvDcc8+xZs0aAD744ANee+21jGW2a2pqWLZsGRA8x2HdunUHLLcrZbabm5uZM2cO8+fPp0ePYDN8//33OeSQQ+jXrx9vvfUWjz32GBCUAV+3bh2vv/46AD/+8b5jh61bt3LcccFmNW/evE5/V0QyizIppDq0S3dIOgX4mbvvSbkgs+lmttTMlmZ6rGQ2pk2Dxkaorg4edFFdHYxPm5bXYveTXDr7nHPO4YorrmDs2LGccsopXHrppWzbtm2/0tmTJ09OWzob4Jvf/CYDBgxIvJ577jl++MMf8utf/zpxZrBo0aJO4zrqqKOYN28eU6dO5dRTT2XMmDGsWrVqvzLb48eP55hjjqFfv34ATJ48mXfffZfa2lq++93vcuKJJx6w3GnTprF06VLq6+tpamrKqsz23XffzbvvvsuECROora3l85//PKeddhojR45kxIgRfO5zn0s0c1VVVdHY2MjEiRMZP3481dXVieXceOON3HzzzZx++uns2ZNy8xGRHERWOtvMxgIN7n5uOH4zgLv/3xTz/h641t1/29lyVTo7GuVeZlvbiFS6Yiid/SIwxMwGm9lBBGcDCzvOZGYnAR8GfhdhLNIJldkW6VwplL7OV6QP2TGz84FvAz2BB9z9NjObTXBp1MJwngagyt1nZrNMnSlIV2gbke5gtu+xmqUm2zOFSJ+n4O6LgEUdpt3SYbyhm34rr6t5pHxFeeAjUm7K4o7mqqoqtmzZov/8cgB3Z8uWLVRVVcUdipSohobgDKH9mLN9uFybksriGc1tbW20trbqGnVJqaqqigEDBtC7d++4Q5ESp+ajEtG7d+/E3bgiItJ1ZdF8JCJSCEk1GsuWkoKISJbKtR8hmZKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgoiIJCgpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgohUjEooU5EvJQURqRi33hp3BMVPSUFERBKUFESkrFXak9PyVRZPXhMRyUYpPzktX9k+eU1nCiIikqCkICIVoxKenJYvJQURqRjqR+ickoKIiCQoKYiISIKSgoiIJCgpiIhIQq9sZjKz44Dq5Pnd/dmoghIRkXh0mhTM7A7gcmAFsCec7ICSgohImcnmTOFi4CR3/2vUwYhIcWto0GWd5S6bPoW1QO+oAxGR4qcqo+UvmzOFD4AWM3sSSJwtuPuMyKISEZFYZHOmsBD4BvBboDnpJSIVoJiqjKrpKnpZVUk1s4OAE8PRV929LdKoMlCVVJH4xF1lNO7fL2V5VUk1s8OThj8GrAbmAvcAr5nZmVkGcZ6ZvWpma8xsZpp5/sHMVpjZcjP7UTbLFRGRaKRrPppsZlPD4W8B57j7R939TOBc4D86W7CZ9SRIJJ8EhgNTzWx4h3mGADcDp7v7COCfu/ZniEghxFFltJiarypByqTg7vcDg8LR3u7+atJnr5Hd1UijgTXuvtbddwELgIs6zPMFYK67/zlc9ts5xi8iBRRXP4L7vmaj9mElhWik7Wh29zvCwaVmdr+ZfSx83Ud2Hc3HAW8mjbeG05KdCJxoZs+Z2fNmdl4uwYuISPfK5pLULwHXAjMAI7iT+Z4svmcppnXsIuoFDAE+BgwAfmNmJ7v7e/styGw6MB1g0KBBiEhl0kNyotdpUgjvZP738JWLVmBg0vgA4I8p5nk+vJppnZm9SpAkXuwQQyPQCMHVRznGISJlQk1G0UvbfGRmPwnf/2BmL3d8ZbHsF4EhZjY4vKR1CsE9D8l+DkwIf6c/QXPS2q78ISIikr9MZwrXh+8XdGXB7r7bzK4DHgd6Ag+4+3Izmw0sdfeF4WfnmFl7sb1/dfctXfk9ERHJX6c3r5nZYGCTu+8Mxw8GjnH39dGHdyDdvCYikru8bl7r4KfA3qTxPeE0EREpM9kkhV7hfQYAhMMHRReSiJQrdRQXv2ySwmYzm9Q+YmYXAe9EF5KIlCuV3i5+2dyncA3QZGZ3E9x78Cbwj5FGJSIisej0TMHdX3f3MQT1i4a7+zh3XxN9aCJSDlS7qLRkWzp7IjACqGqf5u6zI4wrLV19JFK6VPo6Pt129ZGZ3QtcDvwTQfPRZUB13hGKiEjRyaajeZy7/yPwZ3e/FRjL/uUrRESyotpFxS+bpLAjfP/AzP4WaAMGRxeSiJQr9SMUv2yuPno0fBLbncAygkqn3480KhERiUU2VVK/EQ7+l5k9ClS5+9ZowxIRkTikTQpmdkmGz3D3h6IJSURE4pLpTOHC8P1oYBzw63B8AvA0oKQgIlJm0iYFd/8sQNhkNNzdN4XjxwJzCxOeiIgUUjZXH9W0J4TQWwQPwxERkTKTzdVHT5vZ48CPCa48mgI8FWlUIiISi2yuProu7HQ+I5zU6O4PRxuWiIjEIZszhfYrjdSxLCJS5jJdkrrE3ceb2TaCZqPER4C7+2GRRyciIgWV6eqj8eF738KFIyIiccp0pnBEpi+6+7vdH46IiMQpU59CM0GzkaX4zIHjI4lIRERik6n5SJVQRUQqTFZXH5nZh4Eh7P/ktWejCkpEROLRaVIws88D1wMDgBZgDPA74OPRhiYiIoWWTZmL64GPABvcfQIwEtgcaVQiIhKLbJLCTnffCWBmH3L3VcBJ0YYlIiJxyKZPoTV88trPgSfM7M/AH6MNS0RE4pBN7aNPhYMNZvYU0A/4ZaRRiYhILDLdvPb/gR8BP3f3vwC4+zOFCkxERAovU59CI3ABsN7MHjSzi83soALFJSIRaGiIOwIpdmmTgrv/wt2nAoMIKqReCbxhZg+Y2dmFClBEus+tt8YdgRS7Tq8+cvcd7v5g2LdwDsElqepTEBEpQ50mBTM7xsz+ycyeI7gCaTEwKvLIRKRbNDSAWfCCfcNqSpJU0iYFM/uCmf0aWEbwTOYb3f14d7/J3VuyWbiZnWdmr5rZGjObmeLzq8xss5m1hK/Pd/kvEZGUGhrAPXjBvmElBUkl0yWp44DbgV+5+95cF2xmPYG5wNlAK/CimS109xUdZn3Q3a/LdfkiItL9MlVJ/Wyeyx4NrHH3tQBmtgC4COiYFESkQGbNijsCKXbZlLnoquOAN5PGW8NpHU02s5fN7GdmNjDCeEQqnpqMpDNRJoV0D+dJ9ghQ4+6nAr8CfpByQWbTzWypmS3dvFm1+EREopJ1UjCzo81sUPsri6+0AslH/gPoUDPJ3be4+1/D0ftIc1WTuze6e7271x911FHZhiwiIjnK5pLUSWa2GlgHPAOsBx7LYtkvAkPMbHB4J/QUYGGHZR+bNDoJWJll3CIiEoFszhS+QfBgndfCR3R+Aniusy+5+27gOuBxgp39T9x9uZnNNrNJ4WwzzGy5mb0EzACu6sLfICIi3SSbpNDm7luAHmbWw92fAmqzWbi7L3L3E939BHe/LZx2i7svDIdvdvcR7n6au08In9UgImmoo1iilk1SeM/MDgWeBZrM7DvA7mjDEpFUVLtIopZNUrgI2AHcQFDz6HXgwiiDEhGReGRTEO8v7r7H3Xe7+w/c/a6wOUlECkC1i6SQzL3jrQPhB2bbOPC+ggR3PyyqoDKpr6/3pUuXxvHTIrEz21fDSCQXZtbs7vWdzZepzEXfcEGzgT8BPyS4IW0a0Leb4hQRkSKSTZ/Cue5+j7tvc/f33f27wOSoAxORA6l2kUQtm6Swx8ymmVlPM+thZtOAPVEHJiIHUj+CRC2bpHAF8A/AW+HrsnCaiIiUmUzPUwDA3dcTXJYqIiJlLm1SMLMb3f3fzOw/SXEVkrvPiDQykTLT0KDmHyl+mZqP2ovTLQWaU7xEJAe6G1lKQaZLUh8J31M+40BERMpP2jMFM3vEzBamexUySJFSpbuRpdRkuqP5o+HgJcDfAPPD8anAenf/avThHUh3NEup0t3IEqfuuKP5mXBB33D3M5M+esTMnu2GGEVEpMhkc5/CUWZ2fPuImQ0G9ExMkRzpbmQpBZ3ep0BQMvtpM1sbjtcA0yOLSKRMqR9BSkHGpGBmPYD3gSHA0HDyKnf/a9SBiYhI4WVMCu6+18y+5e5jgZcKFJOIiMQkmz6FxWY22az9ojoRESlX2fQpfAU4hKBa6g6CZyp4XA/ZERGR6GTzOM6+7t7D3Xu7+2HhuBKCVBx1FEsl6DQpWODTZvb1cHygmY2OPjSR4qLaRVIJUiYFMzvdzHqGo/cAY9n3DIXtwNwCxCYiIgWW7kzBge+Gw3/v7tcCOwHc/c/AQQWITSR2ql0klSZlR7O7/9bMPghH28KzBgcws6OAvQWKTyRWyc9AUO0iqQRp+xTcvSUcvAt4GDjazG4DlgD/pwCxiUioqQlqaqBHj+C9qSnuiKRcZfM4ziYzawY+QXA56sXuvrKTr4mUnbhqFzU1wfTp8EF47r5hQzAOMG1aPDFJ+cpUOrsKuAb4O+APwP3uvruAsaWk0tlSaWpqgkTQUXU1rF9f6GikVGVbOjvTJak/AOoJEsIngTndFJuI5OCNN3KbLuWnkM2HmZLCcHf/tLt/D7gUODPDvCISkUGDcpsuxSefnXp78+GGDcGFDu3Nh1ElhkxJoa19oBiajUQq1W23QZ8++0/r0yeYXioquaM835361762rz+p3QcfBNOjkCkpnGZm74evbcCp7cNm9n404YhIR9OmQWNj0IdgFrw3NubWyRznTrnQR7pRyGf95btTL3TzYdqO5mKljmaR3HS8egmCM41cE0tXlXpHeb7rr0eP1Pe3mMHeLO746q711x0dzXkzs/PM7FUzW2NmMzPMd6mZuZl1GrBIqYm76aTQzQ8dFUNHeZxH+vn2CRW8+dDdI3kBPYHXgeMJymK8RNB53XG+vsCzwPNAfWfLHTVqlIuUivnz3fv0cQ+OFYNXnz7B9EIx2//3219mhfn96urUv19dnf0y5s8P5jcL3nNZf/n+G+S7/rpjG8jn728HLPVs9t3ZzNSVF0ERvceTxm8Gbk4x37eBC4CnlRQkSrNmFf43u2OHWAwxxLlTzvf7+f79ca+/7lIMSeFS4PtJ458B7u4wz0jgv8JhJQWJVPBsqMKK+yjdPf6dcvsyurpTzHenXAxH+sWgGJLCZSmSwn8mjfcIE0GNd5IUgOnAUmDpoEGDIltp5aoYjlKKQRxJoRjOFNzj3SnnK9+derkc6eerGJJCxuYjoB/wDrA+fO0E/tjZ2YLOFHJTLkc5XTVrVuodQi5NSXE2nRSDuM928t2pl8O/QXcohqTQC1gLDE7qaB6RYX41H0Ug7qO8YtKVM4W4m06KQdzbkP4NukfsSSGIgfOB18KrkL4WTpsNTEoxr5JCBOI+yismXUkKce8Qi0ExHGlrp56/bJOCbl4rc6V+41Cy5AfeFOr7+d54VC6amoLr8t94I7i+/rbbVLa71GR785qSQpmL+27W7hTHk8/KKalKZSuKO5olft1RN6fU5XM3azkUoxPJRUUkhbjLDMRt2rTgqHbv3uC9lBJCQ0OQzMyC8fbhbJuB8i3GpqQqlabsm4/Kqfmk0nWl+UjNPyIBNR+F4i4GJvlrP9OD3M/0iqEYm0gpKfukoJ1CaUtu/oHcm3/01DKR3JR9UtBOobTle6anjmKR3JR9UtBOoXh05R6DfM/01FEskpuy72gG3XhTLNRRLBIfdTQnKeVLMiudzvRECqsikoLEJ9/7DNT8I1JYFdF8JMUhjjIVIhJQ85GIiORMSUEil8/NZyJSWL3iDkDKW8cyI+03n4H6BUSKkc4UJFIqMyJSWpQUpFP5VJlVmRGR0lJRSSGfp3ZVqnxLT6vMiEhpqaikcOut8fxuKT/PQbWHRCpLRSWFrspnp57vkXbcVHtIpLKUfVKI+8ldpd7R2h3NPyozIlI6KiIpuO+7k7Z9ONukkO9OvTs6WuNsflLzj0hlKfukkK98d+r5HmnH3fyk5h+RylJRSWHWrNy/k+9OPd8j7WJoflLzj0jlqKik0JVLUvPdqed7pF1M1/nrkl6R8qcqqVmI8yE9xfSQGVU5FSldqpLajeJsPlFHr4gUkpJCkYu7ozffS3pFpLSo+UiypuYjkdKl5iM5gI7uRaQzSgoVJN/aT125pFdESouSgmRNZxoi5U9Jocypo1hEcqGkUEBx7Ijzrf0kIpVFSSEH+e5I43qeg4hItiJNCmZ2npm9amZrzGxmis+vMbM/mFmLmS0xs+FRxpOvUt+pq6NYRDoTWVIws57AXOCTwHBgaoqd/o/c/RR3rwX+Dfj3qOKJSzG16avJSEQ6E+WZwmhgjbuvdfddwALgouQZ3P39pNFDgKK7NSrfnbra9EWklPSKcNnHAW8mjbcCf99xJjO7FvgKcBDw8VQLMrPpwHSAQQV+4ntDw74duO7oFZFyF+WZgqWYdsAu1d3nuvsJwE3A/061IHdvdPd6d68/6qijujnMwsm3TV9nFyIStSiTQiswMGl8APDHDPMvAC6OMJ68xb1TL/WObhEpflEmhReBIWY22MwOAqYAC5NnMLMhSaMTgdURxpM3HamLSLmLLCm4+27gOuBxYCXwE3dfbmazzWxSONt1ZrbczFoI+hWujCqeUlVMVy+JSPlT6ewSoo5uEekqlc4WEZGcKSmUEN2RLCJRU1IoIepHEJGoKSmIiEiCkoKIiCQoKYiISIKSgoiIJCgpiIhIQsndvGZmm4ENcceRRn/gnbiDyEDx5afY44Pij1Hx5Sef+KrdvdOKoiWXFIqZmS3N5o7BuCi+/BR7fFD8MSq+/BQiPjUfiYhIgpKCiIgkKCl0r8a4A+iE4stPsccHxR+j4stP5PGpT0FERBJ0piAiIglKCjkys4Fm9pSZrQwfEHR9ink+ZmZbzawlfN1S4BjXm9kfwt8+4OETFrjLzNaY2ctmVlfA2E5KWi8tZva+mf1zh3kKvv7M7AEze9vMXkmadoSZPWFmq8P3D6f57pXhPKvNrNsfFJUmtjvNbFX47/ewmR2e5rsZt4WIY2wws41J/47np/nueWb2arg9zixgfA8mxbY+fNhXqu9Gug7T7VNi2/7cXa8cXsCxQF043Bd4DRjeYZ6PAY/GGON6oH+Gz88HHgMMGAP8d0xx9gT+RHD9dKzrDzgTqANeSZr2b8DMcHgmcEeK7x0BrA3fPxwOf7gAsZ0D9AqH70gVWzbbQsQxNgD/K4tt4HXgeOAg4KWO/5+iiq/D598CboljHabbp8S1/elMIUfuvsndl4XD2wgeNXpcvFHl7CLg/3ngeeBwMzs2hjg+Abzu7rHfjOjuzwLvdph8EfCDcPgHwMUpvnou8IS7v+vufwaeAM6LOjZ3X+zBI28BngcGdOdv5irN+svGaGCNu691913AAoL13q0yxWdmBvwD8OPu/t1sZNinxLL9KSnkwcxqgJHAf6f4eKyZvWRmj5nZiIIGBg4sNrNmM5ue4vPjgDeTxluJJ7FNIf1/xDjXX7tj3H0TBP9xgaNTzFMM6/JzBGd+qXS2LUTturCJ64E0zR/FsP7OAN5y99VpPi/YOuywT4ll+1NS6CIzOxShOjUFAAAEDElEQVT4L+Cf3f39Dh8vI2gSOQ34T+DnBQ7vdHevAz4JXGtmZ3b43FJ8p6CXoZnZQcAk4KcpPo57/eUi1nVpZl8DdgNNaWbpbFuI0neBE4BaYBNBE01HsW+LwFQynyUUZB12sk9J+7UU0/Jaf0oKXWBmvQn+8Zrc/aGOn7v7++6+PRxeBPQ2s/6Fis/d/xi+vw08THCKnqwVGJg0PgD4Y2GiS/gksMzd3+r4QdzrL8lb7c1q4fvbKeaJbV2GnYoXANM8bGDuKIttITLu/pa773H3vcB9aX471m3RzHoBlwAPppunEOswzT4llu1PSSFHYfvj/cBKd//3NPP8TTgfZjaaYD1vKVB8h5hZ3/Zhgg7JVzrMthD4x/AqpDHA1vbT1AJKe3QW5/rrYCHQfjXHlcAvUszzOHCOmX04bB45J5wWKTM7D7gJmOTuH6SZJ5ttIcoYk/upPpXmt18EhpjZ4PDscQrBei+Us4BV7t6a6sNCrMMM+5R4tr+oetTL9QWMJzg9exloCV/nA9cA14TzXAcsJ7iS4nlgXAHjOz783ZfCGL4WTk+Oz4C5BFd9/AGoL/A67EOwk++XNC3W9UeQoDYBbQRHX1cDRwJPAqvD9yPCeeuB7yd993PAmvD12QLFtoagLbl9G7w3nPdvgUWZtoUCrr8fhtvXywQ7uGM7xhiOn09wxc3rUcWYKr5w+rz27S5p3oKuwwz7lFi2P93RLCIiCWo+EhGRBCUFERFJUFIQEZEEJQUREUlQUhARkQQlBZGQme2x/Su4dlvFTjOrSa7QKVKsesUdgEgR2eHutXEHIRInnSmIdCKsp3+Hmb0Qvv4unF5tZk+GBd+eNLNB4fRjLHjGwUvha1y4qJ5mdl9YM3+xmR0czj/DzFaEy1kQ058pAigpiCQ7uEPz0eVJn73v7qOBu4Fvh9PuJihBfipBQbq7wul3Ac94UNCvjuBOWIAhwFx3HwG8B0wOp88ERobLuSaqP04kG7qjWSRkZtvd/dAU09cDH3f3tWHhsj+5+5Fm9g5B6Ya2cPomd+9vZpuBAe7+16Rl1BDUvR8Sjt8E9Hb3b5rZL4HtBNVgf+5hMUCROOhMQSQ7nmY43Typ/DVpeA/7+vQmEtSiGgU0h5U7RWKhpCCSncuT3n8XDv+WoKonwDRgSTj8JPAlADPraWaHpVuomfUABrr7U8CNwOHAAWcrIoWiIxKRfQ62/R/e/kt3b78s9UNm9t8EB1JTw2kzgAfM7F+BzcBnw+nXA41mdjXBGcGXCCp0ptITmG9m/Qiq1/6Hu7/XbX+RSI7UpyDSibBPod7d34k7FpGoqflIREQSdKYgIiIJOlMQEZEEJQUREUlQUhARkQQlBRERSVBSEBGRBCUFERFJ+B+/+OFrVq8/ZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_l2_val_loss = entrenamiento_red_l2.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Red Original')\n",
    "plt.plot(epochs, red_l2_val_loss, 'bo', label='Red L2-regularizada')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Pérdida Validación')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Como se puede observar, el modelo que hace uso de Regularización L2 se ha hecho mucho más resistente al sobreajuste que el original, incluso teniendo el mismo número de parámetros.\n",
    "\n",
    "En Keras proporciona funciones para usar regularización L2, regularización L1, e incluso una combinación de ambas, como muestra el siguiente chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x2362440c278>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "# Regularización L1\n",
    "regularizers.l1(0.001)\n",
    "\n",
    "# Regularizaciones L1 y L2 simutáneamente\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "**Dropout** es una de las técnicas de regularización más efectivas y más comúnmente utilizadas para las redes neuronales, desarrollada por Hinton y su equipo de estudiantes de la Universidad de Toronto en 2014 (http://jmlr.org/papers/v15/srivastava14a.html). \n",
    "\n",
    "El Dropout, aplicado a una capa, consiste en la _eliminación aleatoria_ (lo que se traduce en poner a 0) de un número de características de salida de la capa durante el entrenamiento:\n",
    "\n",
    "Supongamos que una capa devolviese un vector `[0.2, 0.5, 1.3, 0.8, 1.1]` para una de las muestras de entrada durante el entrenamiento. Tras la aplicación del Dropout, este vector tendrá unas cuantas entradas nulas distribuidas al azar, por ejemplo, `[0, 0.5, 1.3, 0, 1.1]`. \n",
    "\n",
    "![](./imgs/dropout.gif)\n",
    "\n",
    "Esto significa que sus contribuciones a la activación de las neuronas se eliminan temporalmente en la etapa _forwrad_, así como la actualización de cualquiera de sus pesos en la etapa _backward_. Cuando la activación de una neurona se anula, el efecto que pudiera tener en conjunción con otras neuronas con las que está conectada se pierde, por lo que estas otras neuronas han de aprender la misma representación sin considerar su trabajo conjunto, lo que lleva a disponer de representaciones internas más robustas e independientes.\n",
    "\n",
    "La _tasa de dropout_ es la fracción de características que se ponen a 0, y normalmente se ajusta entre 0,2 y 0,5. Y se debe tener en cuenta que, al igual que todas las técnicas de regularización, durante la fase de test no se hace dropout, sino únicamente durante la fase de entrenamiento, que es cuando queremos limitar la capacidad del modelo. Esto conlleva que los valores de salida de la capa durante le test han de reducirse en un factor igual al dropout, con el fin de equilibrar el hecho de que hay más unidades activas que durante el entrenamiento (si no, sería imposible que el modelo respondiese en tiempo de test lo que ha aprendido en el entrenamiento).\n",
    "\n",
    "Es decir, si durante el entrenamiento el resultado es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-11c4b3245ae1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Durante el entrenamiento hemos descartado el 50% de las unidades de salida\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlayer_output\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'layer_output' is not defined"
     ]
    }
   ],
   "source": [
    "# Durante el entrenamiento hemos descartado el 50% de las unidades de salida\n",
    "# layer_output *= np.randint(0, high=2, size=layer_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Entonces en el test hemos de ajustar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En test:\n",
    "# layer_output *= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Como sería incómodo tener que estar considerando este hecho durante el tiempo de test, este proceso se puede implementar haciendo ambas operaciones durante el tiempo de entrenamiento, de forma que no es necesario considerarlo en el momento del test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durante el entrenamiento:\n",
    "# layer_output *= np.randint(0, high=2, size=layer_output.shape)\n",
    "# Y a continuación escalamos para compensar el efecto del dropout\n",
    "# layer_output /= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pero, ¿porqué esta técnica reduce el sobreajuste? La idea central es que la introducción de ruido en los valores de salida de una capa puede romper patrones que no son significativos y que la red empezaría a memorizar si no hubiera ruido presente. \n",
    "\n",
    "Para no tener que hacerlo a mano, Keras proporciona este regularizador por medio de capas `Dropout` que se aplican a las salidas de la capa anterior (es decir, que más que un proceso de regularización que se hace dentro de la capa, se convierte en una capa adicional que se encarga de realizar aplicar esta técnica tras ella):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a introducir dos capas `Dropout` en el modelo anterior para ver si reducen el sobreajuste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_dpt = models.Sequential()\n",
    "red_dpt.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "red_dpt.add(layers.Dropout(0.5))\n",
    "red_dpt.add(layers.Dense(16, activation='relu'))\n",
    "red_dpt.add(layers.Dropout(0.5))\n",
    "red_dpt.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "red_dpt.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "plot_model(red_dpt, to_file='modelDPT_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/modelDPT_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 7s 272us/step - loss: 0.5906 - acc: 0.6839 - val_loss: 0.4324 - val_acc: 0.8620\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 6s 228us/step - loss: 0.4359 - acc: 0.8186 - val_loss: 0.3475 - val_acc: 0.8706\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 6s 238us/step - loss: 0.3469 - acc: 0.8714 - val_loss: 0.2912 - val_acc: 0.8872\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.2881 - acc: 0.8983 - val_loss: 0.2765 - val_acc: 0.8884\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 6s 230us/step - loss: 0.2531 - acc: 0.9136 - val_loss: 0.2802 - val_acc: 0.8884\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 7s 272us/step - loss: 0.2218 - acc: 0.9266 - val_loss: 0.2886 - val_acc: 0.8874\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.1967 - acc: 0.9356 - val_loss: 0.3197 - val_acc: 0.8854\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 6s 228us/step - loss: 0.1762 - acc: 0.9428 - val_loss: 0.3310 - val_acc: 0.8854\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 6s 238us/step - loss: 0.1710 - acc: 0.9450 - val_loss: 0.3578 - val_acc: 0.8851\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 6s 240us/step - loss: 0.1509 - acc: 0.9512 - val_loss: 0.3766 - val_acc: 0.8838\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 6s 252us/step - loss: 0.1456 - acc: 0.9532 - val_loss: 0.3937 - val_acc: 0.8817\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 6s 251us/step - loss: 0.1378 - acc: 0.9567 - val_loss: 0.4366 - val_acc: 0.8757\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 6s 230us/step - loss: 0.1241 - acc: 0.9600 - val_loss: 0.4524 - val_acc: 0.8784\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 6s 238us/step - loss: 0.1198 - acc: 0.9606 - val_loss: 0.4472 - val_acc: 0.8766\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 228us/step - loss: 0.1144 - acc: 0.9630 - val_loss: 0.4957 - val_acc: 0.8729\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 6s 228us/step - loss: 0.1138 - acc: 0.9644 - val_loss: 0.5154 - val_acc: 0.8760\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 240us/step - loss: 0.1083 - acc: 0.9658 - val_loss: 0.5371 - val_acc: 0.8746\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.1102 - acc: 0.9661 - val_loss: 0.5467 - val_acc: 0.8742\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 6s 248us/step - loss: 0.0974 - acc: 0.9683 - val_loss: 0.5750 - val_acc: 0.8730\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 6s 246us/step - loss: 0.1024 - acc: 0.9696 - val_loss: 0.5727 - val_acc: 0.8710\n"
     ]
    }
   ],
   "source": [
    "entrenamiento_red_dpt = red_dpt.fit(x_train, y_train,\n",
    "                               epochs=20,\n",
    "                               batch_size=512,\n",
    "                               validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y comparemos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_dpt_val_loss = entrenamiento_red_dpt.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Red Original')\n",
    "plt.plot(epochs, red_dpt_val_loss, 'bo', label='Red Regularizada Dropout')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Pérdida Validación')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, se observa una clara mejoría respecto de la red original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunos trucos para Dropout\n",
    "\n",
    "El trabajo original sobre Dropout proporciona algunos resultados experimentales sobre algunos problemas estándar de Machine Learning. Como resultado de estos experimentos, ofrecen algunas heurísticas que pueden ser útiles a la hora de usar esta técnica en la práctica:\n",
    "\n",
    "* Por norma general, usa un valor de dropout bajo, entre 0,2 y 0,5. Un valor de 0,2 puede ser un buen punto de partida. Un valor demasiado bajo apenas tiene efecto, y demasiado alto lleva a un aprendizaje muy pobre.\n",
    "* Usa una red más grande. Se tienen mejores resultados cuando se usa sobre redes grandes, algo que da al modelo la posibilidad de aprender representaciones independientes.\n",
    "* Puedes usar dropout tanto en la capa visible (la de entrada) como en las capas ocultas. La aplicación de dropout en cada una de las capas de la red ha dado buenos resultados.\n",
    "* Usa una tasa de aprendizaje grande con cadencia (_decay_) y un momento grande, por ejemplo, multiplica la tasa por un factor entre 10 y 100 y usa valores de momento de 0,9 a 0,99.\n",
    "* Restringe el tamaño de los pesos de la red. Una tasa de aprendizaje alta puede dar lugar a redes con pesos muy altos, así que aplicar una regularización L1 adicional (con tamaños acotados por 4 o 5) puede mejorar mucho los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En resumen, las formas más comunes de prevenir el sobreajuste en redes neuronales son:\n",
    "\n",
    "* Conseguir más (y más variados) datos de entrenamiento. Si el problema lo permite, quizás se pueda usar alguna técnica artificial de _Data Augmentation_.\n",
    "* Parar el entrenamiento cuando se observa que comienza el sobreajuste. Keras proporciona funciones de _early stopping_ para monitorizar si sucede así.\n",
    "* Reducir la capacidad de la red (número de parámetros).\n",
    "* Añadir regularización a los pesos (penalizando configuraciones con pesos muy grandes o más irregulares).\n",
    "* Añadir dropout (añadir ruido con ceros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
