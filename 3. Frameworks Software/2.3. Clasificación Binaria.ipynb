{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación Binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación binaria es, posiblemente, el tipo de problema con mayor número de aplicaciones en ML. En este vamos a ver cómo construir un clasificador en Keras. Concretamente, construiremos una red neuronal que nos ayude a clasificar opiniones de películas como \"positivas/negativas\" únicamente basándonos en el contenido textual de las mismas. Será un ejemplo de lo que se conoce actualmente como **Análisis de Sentimientos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Dataset IMDB\n",
    "\n",
    "Usaremos uno de los datasets que proporciona el sitio [IMDB](https://www.imdb.com) (Internet Movie DataBase) formado por 50,000 opiniones altamente polarizadas (lo que simplifica la tarea de aprendizaje). Este conjunto está dividido en 50%/50% para entrenamiento/test, y en cada uno de ellos hay un 50% de opiniones de cada tipo.\n",
    "\n",
    "AL igual que con el dataset anterior (MNIST) este dataset también viene con Keras, y además se proporciona preprocesado: por medio de un diccionario indexado, las opiniones (secuencias de palabras) se han convertido en secuencias de enteros.\n",
    "\n",
    "El código que carga el dataset (unos 80Mb de datos que serán descargados la primera vez que se ejecuta) es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Como el diccionario es tremendamente grande y hay muchas palabras que se usan rara vez, nos quedaremos solo con las 10,000 palabras más frecuentes (algo que conseguimos por medio del argumento `num_words = 10000` en el proceso de carga). \n",
    "\n",
    "Si quieres, puedes explorar el contenido de las variables `train_data` y `test_data`, que son listas de opiniones, donde cada opinión es una lista de enteros (codificando una secuencia de palabras). Las variables `train_labels` y `test_labels` son listas binarias, donde 0 indica que la opinión asociada es _negativa_ y 1 que es _positiva_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes observar que los índices de las palabras almacenadas están por debajo de 10,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque no es necesario para el entrenamiento posterior, podemos construir funciones que reconstruyen las opiniones a partir de las secuencias de índices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index is a dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "# We reverse it, mapping integer indices to words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# We decode the review; note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "\n",
    "Como las redes neuronales no admiten listas de enteros como entrada, porque son de longitud variable, hemos de añadir un preprocesado adicional para poder trabajar con ellas. Tenemos dos opciones:\n",
    "\n",
    "* Completar las listas más cortas para que todas tengan la misma longitud y, entonces, convertirlas en tensores que alimentarán la capa de entrada de la red.\n",
    "* Codificar en One-hot las listas para convertirlas en vectores de 0s y 1s. Como tenemos un máximo de 10,000 palabras en nuestro vocabulario, cada opinión se convertirá en una lista binaria de 10,000 posiciones indicando qué palabras aparecen en la opinión. En este caso, la primera capa (densa) de nuestra red se conectaría con vectores de longitud 10,000.\n",
    "\n",
    "Optaremos por esta segunda opción, que con el tiempo veremos que tiene más ventajas que la primera. \n",
    "\n",
    "El código que permite hacer esta conversión es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el nuevo aspecto que tendría una opinión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También tendríamos que hacer una conversión con las etiquetas, pero como en este caso ya son vectores binarios, basta convertirlos en numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo la Red\n",
    "\n",
    "Como hemos visto, los datos de entrada son vectores, y las etiquetas son escalares (1s y 0s), así que estamos ante la configuración más sencilla de las posibles para ser trabajadas con una red neuronal, y un tipo de red que funciona bien con este tipo de problemas es una simple pila de capas densas con activaciones `relu`, que en Keras se construyen con la instrucción: `layers.Dense(16, activation='relu')`.\n",
    "\n",
    "En general, en todo tipo de capas, los argumentos más habituales que tendrás que usar serán el número de neuronas en la capa, y el tipo de activación que usarán estas neuronas. En el caso anterior usamos 16 neuronas, lo que significa que esta capa usará 16 dimensiones para intentar estructurar los patrones que encuentre en los datos de entrada según la función objetivo (loss) que deba optimizar. \n",
    "\n",
    "Se puede interpretar intuitivamente que la dimensión de la capa representa cuánta libertad se permite a la red para aprender representaciones internas. Tener más unidades permite aprender representaciones más complejas, pero también aumenta la carga computacional y facilita la memorización de patrones en los datos de entrenamiento (que quizás no sean relevantes para el problema y que puede llevar a un fenómeno de sobreajuste).\n",
    "\n",
    "Respecto a la arquitectura al trabajar con capas densas, hay dos decisiones claves que considerar:\n",
    "\n",
    "* Cuántas capas usar.\n",
    "* Cuántas unidades colocar en cada capa.\n",
    "\n",
    "Aunque no hay reglas generales para saber cómo tomar estas decisiones, sí que hay algunas razones que se pueden aprender con la experiencia y así poder extraer algún conocimiento implícito útil para el diseño de redes. Para este ejemplo, sin una justificación clara, y solo a modo de demostración de las técnicas vamos a usar dos capas intermedias de 16 neuronas cada una, y una tercera capa que tendrá una única salida escalar (que representará la predicción del modelo). Las capas inermedias usarán `relu` como función de activación, y la capa final usará una sigmoide (que tiene una salida en $[0, 1]$).\n",
    "\n",
    "La implementación en Keras, similar a la que ya hicimos para MNIST, es por tanto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "red = models.Sequential()\n",
    "red.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "red.add(layers.Dense(16, activation='relu'))\n",
    "red.add(layers.Dense(1, activation='sigmoid'))\n",
    "plot_model(red, to_file='IMDBModel_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/IMDBModel_plot.png)\n",
    "\n",
    "Siguiendo el mismo patrón que vimos en el ejemplo anterior, necesitamos elegir la función de pérdida (que será minimizada) y el método de optimización (que será el que busque minimizar esa función). \n",
    "\n",
    "Como estamos ante un problema de clasificación binaria y la salida de nuestra red es una probabilidad (proporcionada por la sigmoide), usaremos `binary_crossentropy` como función de pérdida. No es la única opción viable, podríamos haber elegido, por ejemplo, `mean_squared_error`, pero en este caso `binary_crossentropy` es una mejor opción por estar trabajando con probabilidades. La entropía cruzada proviene del campo de **Teoría de la Información**, y mide la distancia entre distribuciones de probabilidad (en este caso, la distribución calculada por el predictor y la que representa la distribución _real_ proveniente de los datos de entrenamiento).\n",
    "\n",
    "Como optimizador usaremos `rmsprop`, que suele ser una buena elección en casi todos los casos. Para monitorear la evolución del aprendizaje usaremos una sola métrica, _accuracy_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso estamos pasando todos los datos como cadenas que vienen predefinidas en Keras y trabajan con parámetros fijos, pero también es posible ajustar con más flexibilidad cada una de ellas y configurar los parámetros de los que depende, e incluso pasarle funciones, ya sean las que trae Keras o completamente personalizadas. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "red.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O incluso de forma más detallada como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "red.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validando el modelo\n",
    "\n",
    "Con el fin de monitorizar la métrica (_accuracy_) mientras se produce el entrenamiento necesitamos tener más datos que el modelo no use durante el proceso. Crearemos para ello un *conjunto de validación* separando otras 10,000 muestras del conjunto original. Así pues la situación queda como:\n",
    "\n",
    "* _Conjunto de entrenamiento_: con el que intentaremos optimizar los pesos de la red para que minimice la función de pérdida. En este proceso se usa un modelo que depende de ciertos parámetros que quizás deban ser ajustados para conseguir mejorar el rendimiento.\n",
    "\n",
    "* _Conjunto de validación_: con el que se medirá cómo de bueno es el modelo concreto que estamos entrenando (con unos parámetros fijos). Es algo así como un conjunto de test temporal. Permite ajustar estos parámetros para mejorar el rendimiento.\n",
    "\n",
    "* _Conjunto de test_: que no se ha usado en ningún momento de las iteraciones anteriores y que permite medir de forma objetiva la bondad del modelo final obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, entrenaremos el modelo realizando 20 iteraciones (_epochs_) sobre el conjunto completo de entrenamiento, ni validación, ni test), en mini-batches de 512 muestras (es decir, cada 512 muestras analizadas, se actualizan los pesos de la red). Monitorearemos _loss_ y _accuracy_ sobre las 10,000 muestras que dejamos en el conjunto de validación. Para ello, usamos el argumento `validation_data` de la función `fit`, que no usamos en el ejemplo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 3s 209us/step - loss: 0.0023 - binary_accuracy: 0.9999 - val_loss: 0.6970 - val_binary_accuracy: 0.8650\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 3s 189us/step - loss: 0.0045 - binary_accuracy: 0.9991 - val_loss: 0.7208 - val_binary_accuracy: 0.8656\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 3s 193us/step - loss: 0.0014 - binary_accuracy: 0.9999 - val_loss: 0.7463 - val_binary_accuracy: 0.8653\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 3s 201us/step - loss: 0.0035 - binary_accuracy: 0.9993 - val_loss: 0.7757 - val_binary_accuracy: 0.8646\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 3s 197us/step - loss: 8.7281e-04 - binary_accuracy: 0.9999 - val_loss: 0.7990 - val_binary_accuracy: 0.8635\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 3s 202us/step - loss: 0.0021 - binary_accuracy: 0.9997 - val_loss: 0.8256 - val_binary_accuracy: 0.8628\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 3s 189us/step - loss: 5.6212e-04 - binary_accuracy: 0.9999 - val_loss: 0.8435 - val_binary_accuracy: 0.8637\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 3s 189us/step - loss: 8.3919e-04 - binary_accuracy: 0.9998 - val_loss: 0.9790 - val_binary_accuracy: 0.8474\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 3s 210us/step - loss: 4.5639e-04 - binary_accuracy: 0.9999 - val_loss: 0.8948 - val_binary_accuracy: 0.8611\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 3s 206us/step - loss: 2.6866e-04 - binary_accuracy: 1.0000 - val_loss: 0.9232 - val_binary_accuracy: 0.8601\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 3s 186us/step - loss: 0.0024 - binary_accuracy: 0.9995 - val_loss: 0.9620 - val_binary_accuracy: 0.8601\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 3s 186us/step - loss: 1.5121e-04 - binary_accuracy: 1.0000 - val_loss: 0.9680 - val_binary_accuracy: 0.8616\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 3s 188us/step - loss: 1.2264e-04 - binary_accuracy: 1.0000 - val_loss: 0.9891 - val_binary_accuracy: 0.8599\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 9.7633e-05 - binary_accuracy: 1.0000 - val_loss: 1.0153 - val_binary_accuracy: 0.8607\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 3s 208us/step - loss: 0.0011 - binary_accuracy: 0.9996 - val_loss: 1.0378 - val_binary_accuracy: 0.8641\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 3s 199us/step - loss: 6.2730e-05 - binary_accuracy: 1.0000 - val_loss: 1.0488 - val_binary_accuracy: 0.8631\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 3s 187us/step - loss: 4.7860e-05 - binary_accuracy: 1.0000 - val_loss: 1.0637 - val_binary_accuracy: 0.8617\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 3s 188us/step - loss: 3.7303e-05 - binary_accuracy: 1.0000 - val_loss: 1.0961 - val_binary_accuracy: 0.8610\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 3s 194us/step - loss: 5.5720e-04 - binary_accuracy: 0.9998 - val_loss: 1.1409 - val_binary_accuracy: 0.8568\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 3s 198us/step - loss: 2.7135e-05 - binary_accuracy: 1.0000 - val_loss: 1.1310 - val_binary_accuracy: 0.8592\n"
     ]
    }
   ],
   "source": [
    "entrenamiento = red.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque no lo usamos en el ejemplo anterior, y tampoco pasamos el resultado a una variable para poder hacerlo, la llamada a `fit()` devuelve un objeto `history`, que tiene la siguiente estructura:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'loss', 'binary_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenamiento_dict = entrenamiento.history\n",
    "entrenamiento_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, este objeto contiene 4 entradas, una por cada métrica que está siendo monitorizada durante el entrenamiento y durante la validación. Podemos usar `Matplotlib` para representar las pérdidas/precisión de entrenamiento y validación simultáneamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ent_acc = entrenamiento.history['binary_accuracy']\n",
    "val_acc = entrenamiento.history['val_binary_accuracy']\n",
    "ent_loss = entrenamiento.history['loss']\n",
    "val_loss = entrenamiento.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(ent_acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, ent_loss, 'bo', label='Entrenamiento')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validación')\n",
    "plt.title('Pérdida en Entrenamiento y Validación')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = entrenamiento_dict['binary_accuracy']\n",
    "val_acc_values = entrenamiento_dict['val_binary_accuracy']\n",
    "\n",
    "plt.plot(epochs, ent_acc, 'bo', label='Entrenamiento')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validación')\n",
    "plt.title('Accuracy en Entrenamiento y Validación')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Estas gráficas muestras que la _pérdida_ de entrenamiento decrece en cada epoch, y que el _accuracy_ en entrenamiento crece, algo que indica que el procedimiento de optimización está funcionando adecuadamente (sobre todo respecto a la función de pérdida). Pero en este caso observamos que no ocurre lo mismo con la validación, que empiezan a empeorar a partir de la epoch 4. Estamos ante un claro caso de *overfitting*: tras unos pocos pasos el sistema se sobreajusta a los datos de entrenamiento, y aprende una representación que es específica a estos datos y que no puede generalizarse a otros datos.\n",
    "\n",
    "En este caso, para prevenir el overfitting podríamos parar el entrenamiento tras las 3 primeras iteraciones. Más adelante veremos algunas otras técnicas para mitigar este efecto, pero por ahora nos contentaremos con este procedimiento que, aún lejos de ser el mejor, evita este problema ahora mismo.\n",
    "\n",
    "Vamos a entrenar una nueva red desde el principio pero solo durante 4 epochs y después evaluaremos el modelo sobre los datos de test (observa que estos datos no los hemos usado en ningún momento hasta ahora):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 4s 149us/step - loss: 0.4632 - acc: 0.8182\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s 123us/step - loss: 0.2659 - acc: 0.9061\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 123us/step - loss: 0.2045 - acc: 0.9273\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 121us/step - loss: 0.1705 - acc: 0.9400\n",
      "25000/25000 [==============================] - 7s 270us/step\n"
     ]
    }
   ],
   "source": [
    "red2 = models.Sequential()\n",
    "red2.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "red2.add(layers.Dense(16, activation='relu'))\n",
    "red2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "red2.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "red2.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = red2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2901304799175262, 0.88524]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la aproximación tan simple que hemos hecho consigue un accuracy del 88% (el estado del arte actual para este problema ronda del 95%, pero trabajando sobre redes mucho más elaboradas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones sobre datos nuevos\n",
    "\n",
    "Tras haber entrenado la red, el paso natural es usar el modelo para algo práctico. Puedes generar nuevas predicciones sobre opiniones para analizar si son positivas o no usando  el método `predict` asociado al modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23330188],\n",
       "       [0.99965847],\n",
       "       [0.934893  ],\n",
       "       ...,\n",
       "       [0.1302816 ],\n",
       "       [0.06781825],\n",
       "       [0.68983537]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verás que el modelo es muy determinante en algunos casos (alcanzando valores como 0.99 o 0.01) pero no tanto en otros (como 0.46)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajo Propuesto\n",
    "\n",
    "* En los modelos anteriores hemos usado 2 capas ocultas... comprueba el efecto de ampliar o reducir este número sobre la accuracy de validación y de test.\n",
    "* Cambia el número de unidades en las capas ocultas (8, 32, 64,...) y mide su efecto.\n",
    "* Mira qué ocurre al usar `mse` como función de pérdida, en vez de `binary_crossentropy`.\n",
    "* Mira qué ocurre al usar la activación `tanh` en vez de `relu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "A pesar de haber analizado únicamente un ejemplo de introducción sin llegar a profundizar en detalles ni experimentar profundamente con los parámetros, podemos ir ya apuntando algunas conclusiones importantes que pueden ayudarnos en casos posteriores:\n",
    "\n",
    "* El trabajo de preprocesamiento sobre los datos es una etapa esencial para que puedas alimentar a las redes (no olvides que se alimentan de tensores).\n",
    "* Las secuencias de palabras se pueden codificar como vectores binarios, aunque hay otras opciones.\n",
    "* Las pilas de capas densas con activaciones `relu` pueden resolver una amplia variedad de problemas... así que no las olvides.\n",
    "* En los problemas de clasificación binaria, la red debería acabar en una capa densa con una sola neurona que haga uso de la activación `sigmoid`. De esta forma, la salida será un único escalar en $[0,1]$ que se puede interpretar como una probabilidad.\n",
    "* En este caso (salida sigmoide en un problema de clasificación binario) una función de pérdida adecuada es `binary_crossentropy`.\n",
    "* El optimizador `rmsprop` es normalmente una buena opción... y para casi todos los problemas.\n",
    "* Cuidado con el *overfitting*. Asegúrate de monitorear la evolución del entrenamiento (acuérdate de preparar un conjunto de validación adicional)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
